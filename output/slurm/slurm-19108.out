------------ Options -------------
amsgrad: True
arch: mconvnet
batch_size: 1
beta1: 0.9
checkpoints_dir: ./checkpoints
continue_train: False
csv: True
dataroot: ./data/datasets/Nodule-50-30K
dataset_mode: classification
dropout: [0.5, 0.5, 0.5]
epoch_count: 1
export_folder: 
fc_n: [2042, 512, 128]
flip_edges: 0.2
gpu_ids: [0]
init_gain: 0.02
init_type: normal
is_train: True
lr: 0.0002
lr_decay_iters: 50
lr_policy: lambda
max_dataset_size: inf
name: Nodule-50-30K-7
ncf: [32, 64, 256, 256]
ninput_edges: 30000
niter: 50
niter_decay: 10
no_vis: False
norm: batch
num_aug: 2
num_groups: 1
num_threads: 2
optimizer: adam
phase: train
plus: False
pool_res: [20000, 15000, 10000, 5000]
print_freq: 9999
resblocks: 0
run_test_freq: 9999
save_epoch_freq: 1
save_latest_freq: 250
scale_verts: False
seed: 16
serial_batches: False
slide_verts: 0.2
validation: True
verbose_plot: False
verbose_train: True
which_epoch: latest
-------------- End ----------------
loaded mean / std from cache
#training meshes = 34
---------- Network initialized -------------
[Network] Total number of parameters : 2.059 M
-----------------------------------------------
saving the latest model (epoch 1, total_steps 1)
loaded mean / std from cache
saving the model at the end of epoch 1, iters 34
learning rate = 0.0002000
Epoch 1/60 | time: 249.5175 - train_acc: 52.94% - train_loss: 0.6983 - val_acc: 16.67% - val_loss: 0.6995
saving the latest model (epoch 2, total_steps 35)
loaded mean / std from cache
saving the model at the end of epoch 2, iters 68
learning rate = 0.0002000
Epoch 2/60 | time: 248.3188 - train_acc: 61.76% - train_loss: 0.6935 - val_acc: 50.00% - val_loss: 0.7024
Early Stopping: val_loss did not lower, patience 1/5
saving the latest model (epoch 3, total_steps 69)
loaded mean / std from cache
saving the model at the end of epoch 3, iters 102
learning rate = 0.0002000
Epoch 3/60 | time: 247.7577 - train_acc: 55.88% - train_loss: 0.6999 - val_acc: 16.67% - val_loss: 0.7184
Early Stopping: val_loss did not lower, patience 2/5
saving the latest model (epoch 4, total_steps 103)
loaded mean / std from cache
saving the model at the end of epoch 4, iters 136
learning rate = 0.0002000
Epoch 4/60 | time: 246.9519 - train_acc: 41.18% - train_loss: 0.6938 - val_acc: 50.00% - val_loss: 0.6938
saving the latest model (epoch 5, total_steps 137)
loaded mean / std from cache
saving the model at the end of epoch 5, iters 170
learning rate = 0.0002000
Epoch 5/60 | time: 246.7332 - train_acc: 41.18% - train_loss: 0.7081 - val_acc: 50.00% - val_loss: 0.6924
saving the latest model (epoch 6, total_steps 171)
loaded mean / std from cache
saving the model at the end of epoch 6, iters 204
learning rate = 0.0002000
Epoch 6/60 | time: 246.2894 - train_acc: 41.18% - train_loss: 0.7024 - val_acc: 50.00% - val_loss: 0.6969
Early Stopping: val_loss did not lower, patience 1/5
saving the latest model (epoch 7, total_steps 205)
loaded mean / std from cache
saving the model at the end of epoch 7, iters 238
learning rate = 0.0002000
Epoch 7/60 | time: 246.1163 - train_acc: 52.94% - train_loss: 0.6940 - val_acc: 66.67% - val_loss: 0.6909
saving the latest model (epoch 8, total_steps 239)
loaded mean / std from cache
saving the model at the end of epoch 8, iters 272
learning rate = 0.0002000
Epoch 8/60 | time: 246.4002 - train_acc: 50.00% - train_loss: 0.6886 - val_acc: 66.67% - val_loss: 0.6884
saving the latest model (epoch 9, total_steps 273)
loaded mean / std from cache
saving the model at the end of epoch 9, iters 306
learning rate = 0.0002000
Epoch 9/60 | time: 246.0731 - train_acc: 58.82% - train_loss: 0.6879 - val_acc: 33.33% - val_loss: 0.7116
Early Stopping: val_loss did not lower, patience 1/5
saving the latest model (epoch 10, total_steps 307)
loaded mean / std from cache
saving the model at the end of epoch 10, iters 340
learning rate = 0.0002000
Epoch 10/60 | time: 245.6757 - train_acc: 61.76% - train_loss: 0.6976 - val_acc: 33.33% - val_loss: 0.7005
saving the latest model (epoch 11, total_steps 341)
loaded mean / std from cache
saving the model at the end of epoch 11, iters 374
learning rate = 0.0002000
Epoch 11/60 | time: 245.3464 - train_acc: 47.06% - train_loss: 0.6857 - val_acc: 50.00% - val_loss: 0.7071
Early Stopping: val_loss did not lower, patience 1/5
saving the latest model (epoch 12, total_steps 375)
loaded mean / std from cache
saving the model at the end of epoch 12, iters 408
learning rate = 0.0002000
Epoch 12/60 | time: 245.3303 - train_acc: 52.94% - train_loss: 0.6829 - val_acc: 50.00% - val_loss: 0.7029
saving the latest model (epoch 13, total_steps 409)
loaded mean / std from cache
saving the model at the end of epoch 13, iters 442
learning rate = 0.0002000
Epoch 13/60 | time: 246.0938 - train_acc: 52.94% - train_loss: 0.6979 - val_acc: 50.00% - val_loss: 0.7010
saving the latest model (epoch 14, total_steps 443)
loaded mean / std from cache
saving the model at the end of epoch 14, iters 476
learning rate = 0.0002000
Epoch 14/60 | time: 245.5584 - train_acc: 50.00% - train_loss: 0.6827 - val_acc: 50.00% - val_loss: 0.7334
Early Stopping: val_loss did not lower, patience 1/5
saving the latest model (epoch 15, total_steps 477)
loaded mean / std from cache
saving the model at the end of epoch 15, iters 510
learning rate = 0.0002000
Epoch 15/60 | time: 246.8124 - train_acc: 55.88% - train_loss: 0.6859 - val_acc: 50.00% - val_loss: 0.7107
saving the latest model (epoch 16, total_steps 511)
loaded mean / std from cache
saving the model at the end of epoch 16, iters 544
learning rate = 0.0002000
Epoch 16/60 | time: 246.7928 - train_acc: 58.82% - train_loss: 0.6885 - val_acc: 50.00% - val_loss: 0.7056
saving the latest model (epoch 17, total_steps 545)
loaded mean / std from cache
saving the model at the end of epoch 17, iters 578
learning rate = 0.0002000
Epoch 17/60 | time: 246.9693 - train_acc: 52.94% - train_loss: 0.6829 - val_acc: 66.67% - val_loss: 0.7111
Early Stopping: val_loss did not lower, patience 1/5
saving the latest model (epoch 18, total_steps 579)
loaded mean / std from cache
saving the model at the end of epoch 18, iters 612
learning rate = 0.0002000
Epoch 18/60 | time: 247.8333 - train_acc: 67.65% - train_loss: 0.7016 - val_acc: 50.00% - val_loss: 0.6941
saving the latest model (epoch 19, total_steps 613)
loaded mean / std from cache
saving the model at the end of epoch 19, iters 646
learning rate = 0.0002000
Epoch 19/60 | time: 248.3418 - train_acc: 47.06% - train_loss: 0.6877 - val_acc: 33.33% - val_loss: 0.7006
Early Stopping: val_loss did not lower, patience 1/5
saving the latest model (epoch 20, total_steps 647)
loaded mean / std from cache
saving the model at the end of epoch 20, iters 680
learning rate = 0.0002000
Epoch 20/60 | time: 247.7434 - train_acc: 55.88% - train_loss: 0.7025 - val_acc: 33.33% - val_loss: 0.7056
Early Stopping: val_loss did not lower, patience 2/5
saving the latest model (epoch 21, total_steps 681)
loaded mean / std from cache
saving the model at the end of epoch 21, iters 714
learning rate = 0.0002000
Epoch 21/60 | time: 247.9438 - train_acc: 55.88% - train_loss: 0.6849 - val_acc: 66.67% - val_loss: 0.7065
Early Stopping: val_loss did not lower, patience 3/5
saving the latest model (epoch 22, total_steps 715)
loaded mean / std from cache
saving the model at the end of epoch 22, iters 748
learning rate = 0.0002000
Epoch 22/60 | time: 248.0330 - train_acc: 52.94% - train_loss: 0.6856 - val_acc: 50.00% - val_loss: 0.7055
saving the latest model (epoch 23, total_steps 749)
loaded mean / std from cache
saving the model at the end of epoch 23, iters 782
learning rate = 0.0002000
Epoch 23/60 | time: 247.9137 - train_acc: 58.82% - train_loss: 0.6746 - val_acc: 50.00% - val_loss: 0.7110
Early Stopping: val_loss did not lower, patience 3/5
saving the latest model (epoch 24, total_steps 783)
loaded mean / std from cache
saving the model at the end of epoch 24, iters 816
learning rate = 0.0002000
Epoch 24/60 | time: 247.4001 - train_acc: 55.88% - train_loss: 0.6768 - val_acc: 66.67% - val_loss: 0.7096
saving the latest model (epoch 25, total_steps 817)
loaded mean / std from cache
saving the model at the end of epoch 25, iters 850
learning rate = 0.0002000
Epoch 25/60 | time: 248.5403 - train_acc: 55.88% - train_loss: 0.6600 - val_acc: 33.33% - val_loss: 0.7206
Early Stopping: val_loss did not lower, patience 3/5
saving the latest model (epoch 26, total_steps 851)
loaded mean / std from cache
saving the model at the end of epoch 26, iters 884
learning rate = 0.0002000
Epoch 26/60 | time: 249.4819 - train_acc: 52.94% - train_loss: 0.6726 - val_acc: 16.67% - val_loss: 0.7186
saving the latest model (epoch 27, total_steps 885)
loaded mean / std from cache
saving the model at the end of epoch 27, iters 918
learning rate = 0.0002000
Epoch 27/60 | time: 249.4531 - train_acc: 50.00% - train_loss: 0.7002 - val_acc: 66.67% - val_loss: 0.7320
Early Stopping: val_loss did not lower, patience 3/5
saving the latest model (epoch 28, total_steps 919)
loaded mean / std from cache
saving the model at the end of epoch 28, iters 952
learning rate = 0.0002000
Epoch 28/60 | time: 249.4824 - train_acc: 41.18% - train_loss: 0.6622 - val_acc: 50.00% - val_loss: 0.6894
saving the latest model (epoch 29, total_steps 953)
loaded mean / std from cache
saving the model at the end of epoch 29, iters 986
learning rate = 0.0002000
Epoch 29/60 | time: 251.1520 - train_acc: 55.88% - train_loss: 0.7023 - val_acc: 50.00% - val_loss: 0.7099
Early Stopping: val_loss did not lower, patience 3/5
saving the latest model (epoch 30, total_steps 987)
loaded mean / std from cache
saving the model at the end of epoch 30, iters 1020
learning rate = 0.0002000
Epoch 30/60 | time: 250.9177 - train_acc: 58.82% - train_loss: 0.6565 - val_acc: 50.00% - val_loss: 0.7467
Early Stopping: val_loss did not lower, patience 4/5
saving the latest model (epoch 31, total_steps 1021)
loaded mean / std from cache
saving the model at the end of epoch 31, iters 1054
learning rate = 0.0002000
Epoch 31/60 | time: 251.1834 - train_acc: 73.53% - train_loss: 0.6964 - val_acc: 33.33% - val_loss: 0.7080
saving the latest model (epoch 32, total_steps 1055)
loaded mean / std from cache
saving the model at the end of epoch 32, iters 1088
learning rate = 0.0002000
Epoch 32/60 | time: 251.2011 - train_acc: 67.65% - train_loss: 0.6595 - val_acc: 50.00% - val_loss: 0.6583
saving the latest model (epoch 33, total_steps 1089)
loaded mean / std from cache
saving the model at the end of epoch 33, iters 1122
learning rate = 0.0002000
Epoch 33/60 | time: 251.4599 - train_acc: 64.71% - train_loss: 0.6571 - val_acc: 33.33% - val_loss: 0.7387
Early Stopping: val_loss did not lower, patience 3/5
saving the latest model (epoch 34, total_steps 1123)
loaded mean / std from cache
saving the model at the end of epoch 34, iters 1156
learning rate = 0.0002000
Epoch 34/60 | time: 252.0187 - train_acc: 55.88% - train_loss: 0.6492 - val_acc: 50.00% - val_loss: 0.7925
Early Stopping: val_loss did not lower, patience 4/5
saving the latest model (epoch 35, total_steps 1157)
loaded mean / std from cache
saving the model at the end of epoch 35, iters 1190
learning rate = 0.0002000
Epoch 35/60 | time: 252.9042 - train_acc: 64.71% - train_loss: 0.6559 - val_acc: 16.67% - val_loss: 0.8250
Early Stopping: val_loss did not lower, patience 5/5
saving the latest model (epoch 36, total_steps 1191)
loaded mean / std from cache
saving the model at the end of epoch 36, iters 1224
learning rate = 0.0002000
Epoch 36/60 | time: 252.8059 - train_acc: 79.41% - train_loss: 0.6318 - val_acc: 16.67% - val_loss: 0.8047
saving the latest model (epoch 37, total_steps 1225)
loaded mean / std from cache
saving the model at the end of epoch 37, iters 1258
learning rate = 0.0002000
Epoch 37/60 | time: 252.7144 - train_acc: 73.53% - train_loss: 0.6045 - val_acc: 16.67% - val_loss: 0.8995
Early Stopping: val_loss did not lower, patience 5/5
saving the latest model (epoch 38, total_steps 1259)
loaded mean / std from cache
saving the model at the end of epoch 38, iters 1292
learning rate = 0.0002000
Epoch 38/60 | time: 252.0307 - train_acc: 55.88% - train_loss: 0.7056 - val_acc: 50.00% - val_loss: 0.8755
saving the latest model (epoch 39, total_steps 1293)
loaded mean / std from cache
saving the model at the end of epoch 39, iters 1326
learning rate = 0.0002000
Epoch 39/60 | time: 251.2102 - train_acc: 76.47% - train_loss: 0.5997 - val_acc: 33.33% - val_loss: 0.6742
saving the latest model (epoch 40, total_steps 1327)
loaded mean / std from cache
saving the model at the end of epoch 40, iters 1360
learning rate = 0.0002000
Epoch 40/60 | time: 250.8717 - train_acc: 85.29% - train_loss: 0.6245 - val_acc: 33.33% - val_loss: 0.8474
Early Stopping: val_loss did not lower, patience 4/5
saving the latest model (epoch 41, total_steps 1361)
loaded mean / std from cache
saving the model at the end of epoch 41, iters 1394
learning rate = 0.0002000
Epoch 41/60 | time: 250.4716 - train_acc: 70.59% - train_loss: 0.5147 - val_acc: 50.00% - val_loss: 0.9263
Early Stopping: val_loss did not lower, patience 5/5
saving the latest model (epoch 42, total_steps 1395)
loaded mean / std from cache
saving the model at the end of epoch 42, iters 1428
learning rate = 0.0002000
Epoch 42/60 | time: 250.8953 - train_acc: 82.35% - train_loss: 0.4477 - val_acc: 33.33% - val_loss: 1.1096
Early Stopping: val_loss did not lower, patience 6/5
Validation loss is stagnating, stopping.
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/Nodule-50-30K-7/latest_net.pth
Mesh         Prediction    Actual
-----------  ------------  --------
110-Izq.obj  nodule        nodule
203-Izq.obj  nodule        nodule
213-Izq.obj  nodule        nodule
218-Izq.obj  nodule        nodule
269-Izq.obj  nodule        nodule
11-Izq.obj   nonodule      nonodule
23-Izq.obj   nodule        nonodule
25-Izq.obj   nonodule      nonodule
28-Izq.obj   nodule        nonodule
5-Izq.obj    nodule        nonodule
Reporte de clasificaci√≥n:
              precision    recall  f1-score   support

      nodule       0.62      1.00      0.77         5
    nonodule       1.00      0.40      0.57         5

    accuracy                           0.70        10
   macro avg       0.81      0.70      0.67        10
weighted avg       0.81      0.70      0.67        10

epoch: -1, TEST ACC: [70.00%], LOSS: 0.666

