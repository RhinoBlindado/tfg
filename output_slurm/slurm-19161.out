------------ Options -------------
amsgrad: True
arch: mconvnet
batch_size: 1
beta1: 0.9
checkpoints_dir: ./checkpoints
continue_train: False
csv: True
dataroot: ./data/datasets/Nodule-50-30K
dataset_mode: classification
dropout: [0.0]
epoch_count: 1
export_folder: 
fc_n: [100]
flip_edges: 0.2
gpu_ids: [0]
init_gain: 0.02
init_type: normal
is_train: True
lr: 0.0002
lr_decay_iters: 50
lr_policy: lambda
max_dataset_size: inf
name: Nodule-50-30K-3
ncf: [16, 16, 32, 64]
ninput_edges: 30000
niter: 50
niter_decay: 10
no_vis: False
norm: group
num_aug: 2
num_groups: 16
num_threads: 2
optimizer: adam
phase: train
plus: False
pool_res: [20000, 15000, 8000, 7500]
print_freq: 9999
resblocks: 0
run_test_freq: 9999
save_epoch_freq: 1
save_latest_freq: 250
scale_verts: False
seed: 16
serial_batches: False
slide_verts: 0.2
validation: True
verbose_plot: False
verbose_train: True
which_epoch: latest
-------------- End ----------------
loaded mean / std from cache
#training meshes = 34
---------- Network initialized -------------
[Network] Total number of parameters : 0.021 M
-----------------------------------------------
saving the latest model (epoch 1, total_steps 1)
loaded mean / std from cache
saving the model at the end of epoch 1, iters 34
learning rate = 0.0002000
Epoch 1/60 | time: 182.7807 - train_acc: 50.00% - train_loss: 0.6949 - val_acc: 50.00% - val_loss: 0.6934
saving the latest model (epoch 2, total_steps 35)
loaded mean / std from cache
saving the model at the end of epoch 2, iters 68
learning rate = 0.0002000
Epoch 2/60 | time: 181.6354 - train_acc: 50.00% - train_loss: 0.6950 - val_acc: 50.00% - val_loss: 0.6936
Early Stopping: val_loss did not lower, patience 1/5
saving the latest model (epoch 3, total_steps 69)
loaded mean / std from cache
saving the model at the end of epoch 3, iters 102
learning rate = 0.0002000
Epoch 3/60 | time: 181.3961 - train_acc: 50.00% - train_loss: 0.6941 - val_acc: 50.00% - val_loss: 0.6933
saving the latest model (epoch 4, total_steps 103)
loaded mean / std from cache
saving the model at the end of epoch 4, iters 136
learning rate = 0.0002000
Epoch 4/60 | time: 181.5564 - train_acc: 50.00% - train_loss: 0.6936 - val_acc: 50.00% - val_loss: 0.6931
saving the latest model (epoch 5, total_steps 137)
loaded mean / std from cache
saving the model at the end of epoch 5, iters 170
learning rate = 0.0002000
Epoch 5/60 | time: 181.3757 - train_acc: 50.00% - train_loss: 0.6939 - val_acc: 50.00% - val_loss: 0.6931
saving the latest model (epoch 6, total_steps 171)
loaded mean / std from cache
saving the model at the end of epoch 6, iters 204
learning rate = 0.0002000
Epoch 6/60 | time: 181.7812 - train_acc: 50.00% - train_loss: 0.6940 - val_acc: 50.00% - val_loss: 0.6931
Early Stopping: val_loss did not lower, patience 1/5
saving the latest model (epoch 7, total_steps 205)
loaded mean / std from cache
saving the model at the end of epoch 7, iters 238
learning rate = 0.0002000
Epoch 7/60 | time: 182.2044 - train_acc: 50.00% - train_loss: 0.6936 - val_acc: 50.00% - val_loss: 0.6928
saving the latest model (epoch 8, total_steps 239)
loaded mean / std from cache
saving the model at the end of epoch 8, iters 272
learning rate = 0.0002000
Epoch 8/60 | time: 181.9177 - train_acc: 50.00% - train_loss: 0.6933 - val_acc: 50.00% - val_loss: 0.6928
Early Stopping: val_loss did not lower, patience 1/5
saving the latest model (epoch 9, total_steps 273)
loaded mean / std from cache
saving the model at the end of epoch 9, iters 306
learning rate = 0.0002000
Epoch 9/60 | time: 181.3742 - train_acc: 50.00% - train_loss: 0.6935 - val_acc: 50.00% - val_loss: 0.6928
Early Stopping: val_loss did not lower, patience 2/5
saving the latest model (epoch 10, total_steps 307)
loaded mean / std from cache
saving the model at the end of epoch 10, iters 340
learning rate = 0.0002000
Epoch 10/60 | time: 181.0250 - train_acc: 50.00% - train_loss: 0.6926 - val_acc: 50.00% - val_loss: 0.6923
saving the latest model (epoch 11, total_steps 341)
loaded mean / std from cache
saving the model at the end of epoch 11, iters 374
learning rate = 0.0002000
Epoch 11/60 | time: 180.2980 - train_acc: 70.59% - train_loss: 0.6912 - val_acc: 66.67% - val_loss: 0.6921
saving the latest model (epoch 12, total_steps 375)
loaded mean / std from cache
saving the model at the end of epoch 12, iters 408
learning rate = 0.0002000
Epoch 12/60 | time: 180.1657 - train_acc: 58.82% - train_loss: 0.6907 - val_acc: 50.00% - val_loss: 0.6923
Early Stopping: val_loss did not lower, patience 1/5
saving the latest model (epoch 13, total_steps 409)
loaded mean / std from cache
saving the model at the end of epoch 13, iters 442
learning rate = 0.0002000
Epoch 13/60 | time: 180.1053 - train_acc: 76.47% - train_loss: 0.6891 - val_acc: 50.00% - val_loss: 0.6907
saving the latest model (epoch 14, total_steps 443)
loaded mean / std from cache
saving the model at the end of epoch 14, iters 476
learning rate = 0.0002000
Epoch 14/60 | time: 179.9030 - train_acc: 50.00% - train_loss: 0.6903 - val_acc: 33.33% - val_loss: 0.6949
Early Stopping: val_loss did not lower, patience 1/5
saving the latest model (epoch 15, total_steps 477)
loaded mean / std from cache
saving the model at the end of epoch 15, iters 510
learning rate = 0.0002000
Epoch 15/60 | time: 179.8048 - train_acc: 70.59% - train_loss: 0.6864 - val_acc: 66.67% - val_loss: 0.6890
saving the latest model (epoch 16, total_steps 511)
loaded mean / std from cache
saving the model at the end of epoch 16, iters 544
learning rate = 0.0002000
Epoch 16/60 | time: 179.1165 - train_acc: 61.76% - train_loss: 0.6882 - val_acc: 50.00% - val_loss: 0.6880
saving the latest model (epoch 17, total_steps 545)
loaded mean / std from cache
saving the model at the end of epoch 17, iters 578
learning rate = 0.0002000
Epoch 17/60 | time: 179.6246 - train_acc: 76.47% - train_loss: 0.6804 - val_acc: 66.67% - val_loss: 0.6830
saving the latest model (epoch 18, total_steps 579)
loaded mean / std from cache
saving the model at the end of epoch 18, iters 612
learning rate = 0.0002000
Epoch 18/60 | time: 179.4880 - train_acc: 82.35% - train_loss: 0.6831 - val_acc: 66.67% - val_loss: 0.6831
Early Stopping: val_loss did not lower, patience 1/5
saving the latest model (epoch 19, total_steps 613)
loaded mean / std from cache
saving the model at the end of epoch 19, iters 646
learning rate = 0.0002000
Epoch 19/60 | time: 179.3208 - train_acc: 79.41% - train_loss: 0.6737 - val_acc: 50.00% - val_loss: 0.6867
Early Stopping: val_loss did not lower, patience 2/5
saving the latest model (epoch 20, total_steps 647)
loaded mean / std from cache
saving the model at the end of epoch 20, iters 680
learning rate = 0.0002000
Epoch 20/60 | time: 179.0417 - train_acc: 55.88% - train_loss: 0.6668 - val_acc: 33.33% - val_loss: 0.6962
Early Stopping: val_loss did not lower, patience 3/5
saving the latest model (epoch 21, total_steps 681)
loaded mean / std from cache
saving the model at the end of epoch 21, iters 714
learning rate = 0.0002000
Epoch 21/60 | time: 178.6950 - train_acc: 52.94% - train_loss: 0.6800 - val_acc: 33.33% - val_loss: 0.6968
Early Stopping: val_loss did not lower, patience 4/5
saving the latest model (epoch 22, total_steps 715)
loaded mean / std from cache
saving the model at the end of epoch 22, iters 748
learning rate = 0.0002000
Epoch 22/60 | time: 179.7067 - train_acc: 61.76% - train_loss: 0.6671 - val_acc: 50.00% - val_loss: 0.6844
saving the latest model (epoch 23, total_steps 749)
loaded mean / std from cache
saving the model at the end of epoch 23, iters 782
learning rate = 0.0002000
Epoch 23/60 | time: 179.8546 - train_acc: 58.82% - train_loss: 0.6599 - val_acc: 33.33% - val_loss: 0.7204
Early Stopping: val_loss did not lower, patience 4/5
saving the latest model (epoch 24, total_steps 783)
loaded mean / std from cache
saving the model at the end of epoch 24, iters 816
learning rate = 0.0002000
Epoch 24/60 | time: 178.7398 - train_acc: 64.71% - train_loss: 0.6328 - val_acc: 50.00% - val_loss: 0.6907
saving the latest model (epoch 25, total_steps 817)
loaded mean / std from cache
saving the model at the end of epoch 25, iters 850
learning rate = 0.0002000
Epoch 25/60 | time: 178.7940 - train_acc: 76.47% - train_loss: 0.6541 - val_acc: 66.67% - val_loss: 0.6737
saving the latest model (epoch 26, total_steps 851)
loaded mean / std from cache
saving the model at the end of epoch 26, iters 884
learning rate = 0.0002000
Epoch 26/60 | time: 178.4141 - train_acc: 79.41% - train_loss: 0.6325 - val_acc: 50.00% - val_loss: 0.7148
Early Stopping: val_loss did not lower, patience 3/5
saving the latest model (epoch 27, total_steps 885)
loaded mean / std from cache
saving the model at the end of epoch 27, iters 918
learning rate = 0.0002000
Epoch 27/60 | time: 179.3145 - train_acc: 55.88% - train_loss: 0.5999 - val_acc: 50.00% - val_loss: 0.6907
saving the latest model (epoch 28, total_steps 919)
loaded mean / std from cache
saving the model at the end of epoch 28, iters 952
learning rate = 0.0002000
Epoch 28/60 | time: 179.5517 - train_acc: 55.88% - train_loss: 0.6291 - val_acc: 33.33% - val_loss: 0.8412
Early Stopping: val_loss did not lower, patience 3/5
saving the latest model (epoch 29, total_steps 953)
loaded mean / std from cache
saving the model at the end of epoch 29, iters 986
learning rate = 0.0002000
Epoch 29/60 | time: 178.3387 - train_acc: 70.59% - train_loss: 0.5871 - val_acc: 50.00% - val_loss: 0.8180
saving the latest model (epoch 30, total_steps 987)
loaded mean / std from cache
saving the model at the end of epoch 30, iters 1020
learning rate = 0.0002000
Epoch 30/60 | time: 177.8316 - train_acc: 88.24% - train_loss: 0.5457 - val_acc: 50.00% - val_loss: 0.8567
Early Stopping: val_loss did not lower, patience 3/5
saving the latest model (epoch 31, total_steps 1021)
loaded mean / std from cache
saving the model at the end of epoch 31, iters 1054
learning rate = 0.0002000
Epoch 31/60 | time: 178.2328 - train_acc: 79.41% - train_loss: 0.5582 - val_acc: 50.00% - val_loss: 0.6874
saving the latest model (epoch 32, total_steps 1055)
loaded mean / std from cache
saving the model at the end of epoch 32, iters 1088
learning rate = 0.0002000
Epoch 32/60 | time: 177.8274 - train_acc: 79.41% - train_loss: 0.5387 - val_acc: 50.00% - val_loss: 0.9701
Early Stopping: val_loss did not lower, patience 3/5
saving the latest model (epoch 33, total_steps 1089)
loaded mean / std from cache
saving the model at the end of epoch 33, iters 1122
learning rate = 0.0002000
Epoch 33/60 | time: 177.8758 - train_acc: 79.41% - train_loss: 0.4877 - val_acc: 50.00% - val_loss: 1.0393
Early Stopping: val_loss did not lower, patience 4/5
saving the latest model (epoch 34, total_steps 1123)
loaded mean / std from cache
saving the model at the end of epoch 34, iters 1156
learning rate = 0.0002000
Epoch 34/60 | time: 177.6494 - train_acc: 73.53% - train_loss: 0.5177 - val_acc: 50.00% - val_loss: 1.0235
saving the latest model (epoch 35, total_steps 1157)
loaded mean / std from cache
saving the model at the end of epoch 35, iters 1190
learning rate = 0.0002000
Epoch 35/60 | time: 177.4144 - train_acc: 88.24% - train_loss: 0.4658 - val_acc: 50.00% - val_loss: 1.0129
saving the latest model (epoch 36, total_steps 1191)
loaded mean / std from cache
saving the model at the end of epoch 36, iters 1224
learning rate = 0.0002000
Epoch 36/60 | time: 177.4007 - train_acc: 85.29% - train_loss: 0.5512 - val_acc: 50.00% - val_loss: 0.9193
saving the latest model (epoch 37, total_steps 1225)
loaded mean / std from cache
saving the model at the end of epoch 37, iters 1258
learning rate = 0.0002000
Epoch 37/60 | time: 176.9112 - train_acc: 85.29% - train_loss: 0.4201 - val_acc: 66.67% - val_loss: 0.7064
saving the latest model (epoch 38, total_steps 1259)
loaded mean / std from cache
saving the model at the end of epoch 38, iters 1292
learning rate = 0.0002000
Epoch 38/60 | time: 176.8097 - train_acc: 82.35% - train_loss: 0.4304 - val_acc: 16.67% - val_loss: 1.1949
Early Stopping: val_loss did not lower, patience 1/5
saving the latest model (epoch 39, total_steps 1293)
loaded mean / std from cache
saving the model at the end of epoch 39, iters 1326
learning rate = 0.0002000
Epoch 39/60 | time: 177.1164 - train_acc: 76.47% - train_loss: 0.5454 - val_acc: 33.33% - val_loss: 1.0245
saving the latest model (epoch 40, total_steps 1327)
loaded mean / std from cache
saving the model at the end of epoch 40, iters 1360
learning rate = 0.0002000
Epoch 40/60 | time: 177.0534 - train_acc: 82.35% - train_loss: 0.3661 - val_acc: 50.00% - val_loss: 1.2469
Early Stopping: val_loss did not lower, patience 1/5
saving the latest model (epoch 41, total_steps 1361)
loaded mean / std from cache
saving the model at the end of epoch 41, iters 1394
learning rate = 0.0002000
Epoch 41/60 | time: 176.9858 - train_acc: 85.29% - train_loss: 0.3950 - val_acc: 33.33% - val_loss: 1.1279
saving the latest model (epoch 42, total_steps 1395)
loaded mean / std from cache
saving the model at the end of epoch 42, iters 1428
learning rate = 0.0002000
Epoch 42/60 | time: 176.7798 - train_acc: 91.18% - train_loss: 0.3624 - val_acc: 50.00% - val_loss: 1.3610
Early Stopping: val_loss did not lower, patience 1/5
saving the latest model (epoch 43, total_steps 1429)
loaded mean / std from cache
saving the model at the end of epoch 43, iters 1462
learning rate = 0.0002000
Epoch 43/60 | time: 176.6469 - train_acc: 97.06% - train_loss: 0.2816 - val_acc: 50.00% - val_loss: 1.5106
Early Stopping: val_loss did not lower, patience 2/5
saving the latest model (epoch 44, total_steps 1463)
loaded mean / std from cache
saving the model at the end of epoch 44, iters 1496
learning rate = 0.0002000
Epoch 44/60 | time: 176.2871 - train_acc: 88.24% - train_loss: 0.1603 - val_acc: 50.00% - val_loss: 1.6758
Early Stopping: val_loss did not lower, patience 3/5
saving the latest model (epoch 45, total_steps 1497)
loaded mean / std from cache
saving the model at the end of epoch 45, iters 1530
learning rate = 0.0002000
Epoch 45/60 | time: 176.5559 - train_acc: 85.29% - train_loss: 0.1918 - val_acc: 33.33% - val_loss: 1.7127
Early Stopping: val_loss did not lower, patience 4/5
saving the latest model (epoch 46, total_steps 1531)
loaded mean / std from cache
saving the model at the end of epoch 46, iters 1564
learning rate = 0.0002000
Epoch 46/60 | time: 176.5666 - train_acc: 82.35% - train_loss: 0.2059 - val_acc: 33.33% - val_loss: 1.8755
Early Stopping: val_loss did not lower, patience 5/5
saving the latest model (epoch 47, total_steps 1565)
loaded mean / std from cache
saving the model at the end of epoch 47, iters 1598
learning rate = 0.0002000
Epoch 47/60 | time: 176.6806 - train_acc: 82.35% - train_loss: 0.3969 - val_acc: 33.33% - val_loss: 1.4308
saving the latest model (epoch 48, total_steps 1599)
loaded mean / std from cache
saving the model at the end of epoch 48, iters 1632
learning rate = 0.0002000
Epoch 48/60 | time: 176.6358 - train_acc: 97.06% - train_loss: 0.4136 - val_acc: 50.00% - val_loss: 1.4455
Early Stopping: val_loss did not lower, patience 5/5
saving the latest model (epoch 49, total_steps 1633)
loaded mean / std from cache
saving the model at the end of epoch 49, iters 1666
learning rate = 0.0001818
Epoch 49/60 | time: 176.4917 - train_acc: 97.06% - train_loss: 0.2164 - val_acc: 50.00% - val_loss: 1.6676
Early Stopping: val_loss did not lower, patience 6/5
Validation loss is stagnating, stopping.
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/Nodule-50-30K-3/latest_net.pth
Mesh         Prediction    Actual
-----------  ------------  --------
110-Izq.obj  nonodule      nodule
203-Izq.obj  nonodule      nodule
213-Izq.obj  nodule        nodule
218-Izq.obj  nonodule      nodule
269-Izq.obj  nodule        nodule
11-Izq.obj   nonodule      nonodule
23-Izq.obj   nodule        nonodule
25-Izq.obj   nodule        nonodule
28-Izq.obj   nodule        nonodule
5-Izq.obj    nodule        nonodule
Reporte de clasificación:
              precision    recall  f1-score   support

      nodule       0.33      0.40      0.36         5
    nonodule       0.25      0.20      0.22         5

    accuracy                           0.30        10
   macro avg       0.29      0.30      0.29        10
weighted avg       0.29      0.30      0.29        10

epoch: -1, TEST ACC: [30.00%], LOSS: 1.475

