------------ Options -------------
amsgrad: False
arch: mconvnet
batch_size: 1
beta1: 0.9
checkpoints_dir: ./checkpoints
continue_train: False
csv: True
dataroot: ./data/datasets/Nodule-98-30K
dataset_mode: classification
dropout: [0.25, 0.25, 0.25]
epoch_count: 1
export_folder: 
fc_n: [2042, 512, 128]
flip_edges: 0.2
gpu_ids: [0]
init_gain: 0.02
init_type: kaiming
is_train: True
lr: 0.0002
lr_decay_iters: 50
lr_policy: lambda
max_dataset_size: inf
name: Nodule-98-30K-GS-2022_07_07__11_59_03
ncf: [32, 64, 256, 256]
ninput_edges: 30000
niter: 30
niter_decay: 10
no_vis: False
norm: batch
num_aug: 20
num_groups: 16
num_threads: 2
optimizer: rmsprop
phase: train
plus: False
pool_res: [20000, 15000, 10000, 5000]
print_freq: 9999
resblocks: 0
run_test_freq: 9999
save_epoch_freq: 1
save_latest_freq: 250
scale_verts: False
seed: 16
serial_batches: False
slide_verts: 0.2
validation: True
verbose_plot: False
verbose_train: True
which_epoch: latest
-------------- End ----------------
loaded mean / std from cache
#training meshes = 66
---------- Network initialized -------------
[Network] Total number of parameters : 2.059 M
-----------------------------------------------
saving the latest model (epoch 1, total_steps 1)
loaded mean / std from cache
saving the model at the end of epoch 1, iters 66
learning rate = 0.0002000
Epoch 1/40 | time: 426.1294 - train_acc: 50.00% - train_loss: 1.2621 - val_acc: 50.00% - val_loss: 0.8339
saving the latest model (epoch 2, total_steps 67)
loaded mean / std from cache
saving the model at the end of epoch 2, iters 132
learning rate = 0.0002000
Epoch 2/40 | time: 426.5674 - train_acc: 56.06% - train_loss: 0.7746 - val_acc: 50.00% - val_loss: 0.6909
saving the latest model (epoch 3, total_steps 133)
loaded mean / std from cache
saving the model at the end of epoch 3, iters 198
learning rate = 0.0002000
Epoch 3/40 | time: 424.7414 - train_acc: 48.48% - train_loss: 0.7927 - val_acc: 41.67% - val_loss: 0.7810
Early Stopping: val_loss did not lower, patience 1/5
saving the latest model (epoch 4, total_steps 199)
loaded mean / std from cache
saving the model at the end of epoch 4, iters 264
learning rate = 0.0002000
Epoch 4/40 | time: 424.9927 - train_acc: 51.52% - train_loss: 0.7117 - val_acc: 25.00% - val_loss: 0.7550
saving the latest model (epoch 5, total_steps 265)
loaded mean / std from cache
saving the model at the end of epoch 5, iters 330
learning rate = 0.0002000
Epoch 5/40 | time: 426.3903 - train_acc: 54.55% - train_loss: 0.7101 - val_acc: 66.67% - val_loss: 0.6745
saving the latest model (epoch 6, total_steps 331)
loaded mean / std from cache
saving the model at the end of epoch 6, iters 396
learning rate = 0.0002000
Epoch 6/40 | time: 425.1341 - train_acc: 54.55% - train_loss: 0.7591 - val_acc: 83.33% - val_loss: 0.6125
saving the latest model (epoch 7, total_steps 397)
loaded mean / std from cache
saving the model at the end of epoch 7, iters 462
learning rate = 0.0002000
Epoch 7/40 | time: 425.4399 - train_acc: 53.03% - train_loss: 0.7038 - val_acc: 58.33% - val_loss: 0.6864
Early Stopping: val_loss did not lower, patience 1/5
saving the latest model (epoch 8, total_steps 463)
loaded mean / std from cache
saving the model at the end of epoch 8, iters 528
learning rate = 0.0002000
Epoch 8/40 | time: 424.2501 - train_acc: 57.58% - train_loss: 0.7376 - val_acc: 83.33% - val_loss: 0.6019
saving the latest model (epoch 9, total_steps 529)
loaded mean / std from cache
saving the model at the end of epoch 9, iters 594
learning rate = 0.0002000
Epoch 9/40 | time: 424.6715 - train_acc: 62.12% - train_loss: 0.6898 - val_acc: 75.00% - val_loss: 0.5530
saving the latest model (epoch 10, total_steps 595)
loaded mean / std from cache
saving the model at the end of epoch 10, iters 660
learning rate = 0.0002000
Epoch 10/40 | time: 423.1556 - train_acc: 62.12% - train_loss: 0.6627 - val_acc: 83.33% - val_loss: 0.5062
saving the latest model (epoch 11, total_steps 661)
loaded mean / std from cache
saving the model at the end of epoch 11, iters 726
learning rate = 0.0002000
Epoch 11/40 | time: 430.0297 - train_acc: 68.18% - train_loss: 0.6521 - val_acc: 91.67% - val_loss: 0.4335
saving the latest model (epoch 12, total_steps 727)
loaded mean / std from cache
saving the model at the end of epoch 12, iters 792
learning rate = 0.0002000
Epoch 12/40 | time: 427.9672 - train_acc: 60.61% - train_loss: 0.6978 - val_acc: 66.67% - val_loss: 0.6123
Early Stopping: val_loss did not lower, patience 1/5
saving the latest model (epoch 13, total_steps 793)
loaded mean / std from cache
saving the model at the end of epoch 13, iters 858
learning rate = 0.0002000
Epoch 13/40 | time: 425.0969 - train_acc: 72.73% - train_loss: 0.6664 - val_acc: 91.67% - val_loss: 0.4733
saving the latest model (epoch 14, total_steps 859)
loaded mean / std from cache
saving the model at the end of epoch 14, iters 924
learning rate = 0.0002000
Epoch 14/40 | time: 423.9464 - train_acc: 60.61% - train_loss: 0.6556 - val_acc: 58.33% - val_loss: 0.5989
Early Stopping: val_loss did not lower, patience 1/5
saving the latest model (epoch 15, total_steps 925)
loaded mean / std from cache
saving the model at the end of epoch 15, iters 990
learning rate = 0.0002000
Epoch 15/40 | time: 424.6852 - train_acc: 65.15% - train_loss: 0.6808 - val_acc: 58.33% - val_loss: 0.5704
saving the latest model (epoch 16, total_steps 991)
loaded mean / std from cache
saving the model at the end of epoch 16, iters 1056
learning rate = 0.0002000
Epoch 16/40 | time: 423.4876 - train_acc: 72.73% - train_loss: 0.6434 - val_acc: 75.00% - val_loss: 0.5338
saving the latest model (epoch 17, total_steps 1057)
loaded mean / std from cache
saving the model at the end of epoch 17, iters 1122
learning rate = 0.0002000
Epoch 17/40 | time: 423.5698 - train_acc: 69.70% - train_loss: 0.6252 - val_acc: 66.67% - val_loss: 0.5861
Early Stopping: val_loss did not lower, patience 1/5
saving the latest model (epoch 18, total_steps 1123)
loaded mean / std from cache
saving the model at the end of epoch 18, iters 1188
learning rate = 0.0002000
Epoch 18/40 | time: 423.3829 - train_acc: 71.21% - train_loss: 0.5877 - val_acc: 75.00% - val_loss: 0.4628
saving the latest model (epoch 19, total_steps 1189)
loaded mean / std from cache
saving the model at the end of epoch 19, iters 1254
learning rate = 0.0002000
Epoch 19/40 | time: 424.1611 - train_acc: 72.73% - train_loss: 0.5677 - val_acc: 91.67% - val_loss: 0.3758
saving the latest model (epoch 20, total_steps 1255)
loaded mean / std from cache
saving the model at the end of epoch 20, iters 1320
learning rate = 0.0002000
Epoch 20/40 | time: 424.5374 - train_acc: 69.70% - train_loss: 0.5392 - val_acc: 75.00% - val_loss: 0.5112
Early Stopping: val_loss did not lower, patience 1/5
saving the latest model (epoch 21, total_steps 1321)
loaded mean / std from cache
saving the model at the end of epoch 21, iters 1386
learning rate = 0.0002000
Epoch 21/40 | time: 428.4057 - train_acc: 65.15% - train_loss: 0.5861 - val_acc: 83.33% - val_loss: 0.4389
saving the latest model (epoch 22, total_steps 1387)
loaded mean / std from cache
saving the model at the end of epoch 22, iters 1452
learning rate = 0.0002000
Epoch 22/40 | time: 427.6334 - train_acc: 74.24% - train_loss: 0.6074 - val_acc: 91.67% - val_loss: 0.4328
saving the latest model (epoch 23, total_steps 1453)
loaded mean / std from cache
saving the model at the end of epoch 23, iters 1518
learning rate = 0.0002000
Epoch 23/40 | time: 423.0571 - train_acc: 72.73% - train_loss: 0.5683 - val_acc: 58.33% - val_loss: 0.5768
Early Stopping: val_loss did not lower, patience 1/5
saving the latest model (epoch 24, total_steps 1519)
loaded mean / std from cache
saving the model at the end of epoch 24, iters 1584
learning rate = 0.0002000
Epoch 24/40 | time: 424.7005 - train_acc: 65.15% - train_loss: 0.6120 - val_acc: 83.33% - val_loss: 0.5338
saving the latest model (epoch 25, total_steps 1585)
loaded mean / std from cache
saving the model at the end of epoch 25, iters 1650
learning rate = 0.0002000
Epoch 25/40 | time: 423.3783 - train_acc: 75.76% - train_loss: 0.5866 - val_acc: 91.67% - val_loss: 0.4502
saving the latest model (epoch 26, total_steps 1651)
loaded mean / std from cache
saving the model at the end of epoch 26, iters 1716
learning rate = 0.0002000
Epoch 26/40 | time: 422.4180 - train_acc: 68.18% - train_loss: 0.4883 - val_acc: 83.33% - val_loss: 0.5958
Early Stopping: val_loss did not lower, patience 1/5
saving the latest model (epoch 27, total_steps 1717)
loaded mean / std from cache
saving the model at the end of epoch 27, iters 1782
learning rate = 0.0002000
Epoch 27/40 | time: 421.9094 - train_acc: 69.70% - train_loss: 0.5712 - val_acc: 58.33% - val_loss: 0.5733
saving the latest model (epoch 28, total_steps 1783)
loaded mean / std from cache
saving the model at the end of epoch 28, iters 1848
learning rate = 0.0002000
Epoch 28/40 | time: 422.0168 - train_acc: 75.76% - train_loss: 0.4695 - val_acc: 75.00% - val_loss: 0.3720
saving the latest model (epoch 29, total_steps 1849)
loaded mean / std from cache
saving the model at the end of epoch 29, iters 1914
learning rate = 0.0001818
Epoch 29/40 | time: 421.7159 - train_acc: 78.79% - train_loss: 0.4650 - val_acc: 83.33% - val_loss: 0.3527
saving the latest model (epoch 30, total_steps 1915)
loaded mean / std from cache
saving the model at the end of epoch 30, iters 1980
learning rate = 0.0001636
Epoch 30/40 | time: 423.0297 - train_acc: 69.70% - train_loss: 0.4649 - val_acc: 83.33% - val_loss: 0.6313
Early Stopping: val_loss did not lower, patience 1/5
saving the latest model (epoch 31, total_steps 1981)
loaded mean / std from cache
saving the model at the end of epoch 31, iters 2046
learning rate = 0.0001455
Epoch 31/40 | time: 420.7357 - train_acc: 78.79% - train_loss: 0.5714 - val_acc: 75.00% - val_loss: 0.5125
saving the latest model (epoch 32, total_steps 2047)
loaded mean / std from cache
saving the model at the end of epoch 32, iters 2112
learning rate = 0.0001273
Epoch 32/40 | time: 423.7619 - train_acc: 81.82% - train_loss: 0.4304 - val_acc: 75.00% - val_loss: 0.4161
saving the latest model (epoch 33, total_steps 2113)
loaded mean / std from cache
saving the model at the end of epoch 33, iters 2178
learning rate = 0.0001091
Epoch 33/40 | time: 421.9483 - train_acc: 86.36% - train_loss: 0.4766 - val_acc: 75.00% - val_loss: 0.6204
Early Stopping: val_loss did not lower, patience 1/5
saving the latest model (epoch 34, total_steps 2179)
loaded mean / std from cache
saving the model at the end of epoch 34, iters 2244
learning rate = 0.0000909
Epoch 34/40 | time: 420.7505 - train_acc: 87.88% - train_loss: 0.3695 - val_acc: 66.67% - val_loss: 0.5634
saving the latest model (epoch 35, total_steps 2245)
loaded mean / std from cache
saving the model at the end of epoch 35, iters 2310
learning rate = 0.0000727
Epoch 35/40 | time: 420.0778 - train_acc: 87.88% - train_loss: 0.3764 - val_acc: 83.33% - val_loss: 0.5614
saving the latest model (epoch 36, total_steps 2311)
loaded mean / std from cache
saving the model at the end of epoch 36, iters 2376
learning rate = 0.0000545
Epoch 36/40 | time: 419.3646 - train_acc: 84.85% - train_loss: 0.4091 - val_acc: 75.00% - val_loss: 0.4475
saving the latest model (epoch 37, total_steps 2377)
loaded mean / std from cache
saving the model at the end of epoch 37, iters 2442
learning rate = 0.0000364
Epoch 37/40 | time: 424.6526 - train_acc: 83.33% - train_loss: 0.3601 - val_acc: 66.67% - val_loss: 0.5179
Early Stopping: val_loss did not lower, patience 1/5
saving the latest model (epoch 38, total_steps 2443)
loaded mean / std from cache
saving the model at the end of epoch 38, iters 2508
learning rate = 0.0000182
Epoch 38/40 | time: 420.2633 - train_acc: 89.39% - train_loss: 0.2965 - val_acc: 66.67% - val_loss: 0.5488
Early Stopping: val_loss did not lower, patience 2/5
saving the latest model (epoch 39, total_steps 2509)
loaded mean / std from cache
saving the model at the end of epoch 39, iters 2574
learning rate = 0.0000000
Epoch 39/40 | time: 421.2408 - train_acc: 86.36% - train_loss: 0.2824 - val_acc: 75.00% - val_loss: 0.6521
Early Stopping: val_loss did not lower, patience 3/5
saving the latest model (epoch 40, total_steps 2575)
loaded mean / std from cache
saving the model at the end of epoch 40, iters 2640
learning rate = -0.0000182
Epoch 40/40 | time: 420.5186 - train_acc: 84.85% - train_loss: 0.2639 - val_acc: 75.00% - val_loss: 0.6832
Early Stopping: val_loss did not lower, patience 4/5
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/Nodule-98-30K-GS-2022_07_07__11_59_03/latest_net.pth
Mesh         Prediction    Actual
-----------  ------------  --------
110-Izq.obj  nonodule      nodule
117-Izq.obj  nodule        nodule
161-Izq.obj  nodule        nodule
216-Izq.obj  nodule        nodule
229-Izq.obj  nodule        nodule
346-Izq.obj  nonodule      nodule
456-Izq.obj  nodule        nodule
475-Izq.obj  nodule        nodule
564-Izq.obj  nonodule      nodule
95-Izq.obj   nonodule      nodule
1-Izq.obj    nonodule      nonodule
15-Izq.obj   nodule        nonodule
19-Izq.obj   nonodule      nonodule
21-Izq.obj   nodule        nonodule
22-Izq.obj   nonodule      nonodule
23-Izq.obj   nonodule      nonodule
35-Izq.obj   nonodule      nonodule
43-Izq.obj   nonodule      nonodule
50-Izq.obj   nonodule      nonodule
7-Izq.obj    nodule        nonodule
Reporte de clasificación:
              precision    recall  f1-score   support

      nodule       0.67      0.60      0.63        10
    nonodule       0.64      0.70      0.67        10

    accuracy                           0.65        20
   macro avg       0.65      0.65      0.65        20
weighted avg       0.65      0.65      0.65        20

epoch: -1, TEST ACC: [65.00%], LOSS: 0.864

------------ Options -------------
amsgrad: False
arch: mconvnet
batch_size: 1
beta1: 0.9
checkpoints_dir: ./checkpoints
continue_train: False
csv: True
dataroot: ./data/datasets/Nodule-98-30K
dataset_mode: classification
dropout: [0.25, 0.25, 0.25]
epoch_count: 1
export_folder: 
fc_n: [2042, 512, 128]
flip_edges: 0.4
gpu_ids: [0]
init_gain: 0.02
init_type: kaiming
is_train: True
lr: 0.0002
lr_decay_iters: 50
lr_policy: lambda
max_dataset_size: inf
name: Nodule-98-30K-GS-2022_07_07__16_43_38
ncf: [32, 64, 256, 256]
ninput_edges: 30000
niter: 30
niter_decay: 10
no_vis: False
norm: batch
num_aug: 40
num_groups: 16
num_threads: 2
optimizer: rmsprop
phase: train
plus: False
pool_res: [20000, 15000, 10000, 5000]
print_freq: 9999
resblocks: 0
run_test_freq: 9999
save_epoch_freq: 1
save_latest_freq: 250
scale_verts: True
seed: 16
serial_batches: False
slide_verts: 0.4
validation: True
verbose_plot: False
verbose_train: True
which_epoch: latest
-------------- End ----------------
loaded mean / std from cache
#training meshes = 66
---------- Network initialized -------------
[Network] Total number of parameters : 2.059 M
-----------------------------------------------
saving the latest model (epoch 1, total_steps 1)
!WARNING! Queue below 100 edges on mesh 203-Izq.obj
!WARNING! Queue below 100 edges on mesh 218-Izq.obj
!WARNING! Queue below 100 edges on mesh 159-Izq.obj
Traceback (most recent call last):
  File "./networks/MeshCNNPlus/development/meshcnn/train.py", line 126, in <module>
    trainAcc = getTrainAcc(model, dataset)
  File "./networks/MeshCNNPlus/development/meshcnn/train.py", line 18, in getTrainAcc
    ncorrect, __, _ = model.test()
  File "/mnt/homeGPU/vlugli/tfg/networks/MeshCNNPlus/development/meshcnn/models/mesh_classifier.py", line 129, in test
    out = self.forward()
  File "/mnt/homeGPU/vlugli/tfg/networks/MeshCNNPlus/development/meshcnn/models/mesh_classifier.py", line 75, in forward
    out = self.net(self.edge_features, self.mesh)
  File "/mnt/homeGPU/vlugli/condaEnvs/meshcnnplus/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/mnt/homeGPU/vlugli/condaEnvs/meshcnnplus/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py", line 159, in forward
    return self.module(*inputs[0], **kwargs[0])
  File "/mnt/homeGPU/vlugli/condaEnvs/meshcnnplus/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/mnt/homeGPU/vlugli/tfg/networks/MeshCNNPlus/development/meshcnn/models/networks.py", line 165, in forward
    x = getattr(self, 'pool{}'.format(i))(x, mesh)
  File "/mnt/homeGPU/vlugli/tfg/networks/MeshCNNPlus/development/meshcnn/models/layers/mesh_pool.py", line 21, in __call__
    return self.forward(fe, meshes)
  File "/mnt/homeGPU/vlugli/tfg/networks/MeshCNNPlus/development/meshcnn/models/layers/mesh_pool.py", line 34, in forward
    self.__pool_main(mesh_index)
  File "/mnt/homeGPU/vlugli/tfg/networks/MeshCNNPlus/development/meshcnn/models/layers/mesh_pool.py", line 51, in __pool_main
    value, edge_id = heappop(queue)
IndexError: index out of range
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/Nodule-98-30K-GS-2022_07_07__16_43_38/latest_net.pth
/mnt/homeGPU/vlugli/condaEnvs/meshcnnplus/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/mnt/homeGPU/vlugli/condaEnvs/meshcnnplus/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/mnt/homeGPU/vlugli/condaEnvs/meshcnnplus/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Mesh         Prediction    Actual
-----------  ------------  --------
110-Izq.obj  nodule        nodule
117-Izq.obj  nodule        nodule
161-Izq.obj  nodule        nodule
216-Izq.obj  nodule        nodule
229-Izq.obj  nodule        nodule
346-Izq.obj  nodule        nodule
456-Izq.obj  nodule        nodule
475-Izq.obj  nodule        nodule
564-Izq.obj  nodule        nodule
95-Izq.obj   nodule        nodule
1-Izq.obj    nodule        nonodule
15-Izq.obj   nodule        nonodule
19-Izq.obj   nodule        nonodule
21-Izq.obj   nodule        nonodule
22-Izq.obj   nodule        nonodule
23-Izq.obj   nodule        nonodule
35-Izq.obj   nodule        nonodule
43-Izq.obj   nodule        nonodule
50-Izq.obj   nodule        nonodule
7-Izq.obj    nodule        nonodule
Reporte de clasificación:
              precision    recall  f1-score   support

      nodule       0.50      1.00      0.67        10
    nonodule       0.00      0.00      0.00        10

    accuracy                           0.50        20
   macro avg       0.25      0.50      0.33        20
weighted avg       0.25      0.50      0.33        20

epoch: -1, TEST ACC: [50.00%], LOSS: 145.312

------------ Options -------------
amsgrad: False
arch: mconvnet
batch_size: 1
beta1: 0.9
checkpoints_dir: ./checkpoints
continue_train: False
csv: True
dataroot: ./data/datasets/Nodule-98-30K
dataset_mode: classification
dropout: [0.5, 0.25, 0.125]
epoch_count: 1
export_folder: 
fc_n: [1024, 512, 128]
flip_edges: 0.2
gpu_ids: [0]
init_gain: 0.02
init_type: kaiming
is_train: True
lr: 0.0002
lr_decay_iters: 50
lr_policy: lambda
max_dataset_size: inf
name: Nodule-98-30K-GS-2022_07_07__16_51_01
ncf: [32, 64, 256, 256]
ninput_edges: 30000
niter: 30
niter_decay: 10
no_vis: False
norm: batch
num_aug: 20
num_groups: 16
num_threads: 2
optimizer: rmsprop
phase: train
plus: False
pool_res: [20000, 15000, 10000, 5000]
print_freq: 9999
resblocks: 0
run_test_freq: 9999
save_epoch_freq: 1
save_latest_freq: 250
scale_verts: False
seed: 16
serial_batches: False
slide_verts: 0.2
validation: True
verbose_plot: False
verbose_train: True
which_epoch: latest
-------------- End ----------------
loaded mean / std from cache
#training meshes = 66
---------- Network initialized -------------
[Network] Total number of parameters : 1.276 M
-----------------------------------------------
saving the latest model (epoch 1, total_steps 1)
loaded mean / std from cache
saving the model at the end of epoch 1, iters 66
learning rate = 0.0002000
Epoch 1/40 | time: 432.3692 - train_acc: 46.97% - train_loss: 1.0892 - val_acc: 66.67% - val_loss: 0.7637
saving the latest model (epoch 2, total_steps 67)
loaded mean / std from cache
saving the model at the end of epoch 2, iters 132
learning rate = 0.0002000
Epoch 2/40 | time: 431.8929 - train_acc: 39.39% - train_loss: 0.8902 - val_acc: 50.00% - val_loss: 0.8032
Early Stopping: val_loss did not lower, patience 1/5
saving the latest model (epoch 3, total_steps 133)
loaded mean / std from cache
saving the model at the end of epoch 3, iters 198
learning rate = 0.0002000
Epoch 3/40 | time: 431.3471 - train_acc: 57.58% - train_loss: 0.7755 - val_acc: 50.00% - val_loss: 0.7181
saving the latest model (epoch 4, total_steps 199)
loaded mean / std from cache
saving the model at the end of epoch 4, iters 264
learning rate = 0.0002000
Epoch 4/40 | time: 431.9966 - train_acc: 50.00% - train_loss: 0.7124 - val_acc: 66.67% - val_loss: 0.5391
saving the latest model (epoch 5, total_steps 265)
loaded mean / std from cache
saving the model at the end of epoch 5, iters 330
learning rate = 0.0002000
Epoch 5/40 | time: 431.9676 - train_acc: 57.58% - train_loss: 0.7603 - val_acc: 58.33% - val_loss: 0.5594
Early Stopping: val_loss did not lower, patience 1/5
saving the latest model (epoch 6, total_steps 331)
loaded mean / std from cache
saving the model at the end of epoch 6, iters 396
learning rate = 0.0002000
Epoch 6/40 | time: 432.1450 - train_acc: 60.61% - train_loss: 0.7905 - val_acc: 58.33% - val_loss: 0.6555
Early Stopping: val_loss did not lower, patience 2/5
saving the latest model (epoch 7, total_steps 397)
loaded mean / std from cache
saving the model at the end of epoch 7, iters 462
learning rate = 0.0002000
Epoch 7/40 | time: 431.5025 - train_acc: 51.52% - train_loss: 0.7803 - val_acc: 50.00% - val_loss: 0.7059
Early Stopping: val_loss did not lower, patience 3/5
saving the latest model (epoch 8, total_steps 463)
loaded mean / std from cache
saving the model at the end of epoch 8, iters 528
learning rate = 0.0002000
Epoch 8/40 | time: 433.2616 - train_acc: 56.06% - train_loss: 0.7207 - val_acc: 58.33% - val_loss: 0.6789
saving the latest model (epoch 9, total_steps 529)
loaded mean / std from cache
saving the model at the end of epoch 9, iters 594
learning rate = 0.0002000
Epoch 9/40 | time: 429.7122 - train_acc: 62.12% - train_loss: 0.7280 - val_acc: 75.00% - val_loss: 0.5850
saving the latest model (epoch 10, total_steps 595)
loaded mean / std from cache
saving the model at the end of epoch 10, iters 660
learning rate = 0.0002000
Epoch 10/40 | time: 429.4150 - train_acc: 59.09% - train_loss: 0.7188 - val_acc: 58.33% - val_loss: 0.6222
Early Stopping: val_loss did not lower, patience 2/5
saving the latest model (epoch 11, total_steps 661)
loaded mean / std from cache
saving the model at the end of epoch 11, iters 726
learning rate = 0.0002000
Epoch 11/40 | time: 430.3736 - train_acc: 59.09% - train_loss: 0.6747 - val_acc: 75.00% - val_loss: 0.6189
saving the latest model (epoch 12, total_steps 727)
loaded mean / std from cache
saving the model at the end of epoch 12, iters 792
learning rate = 0.0002000
Epoch 12/40 | time: 429.1026 - train_acc: 59.09% - train_loss: 0.7331 - val_acc: 66.67% - val_loss: 0.6022
saving the latest model (epoch 13, total_steps 793)
loaded mean / std from cache
saving the model at the end of epoch 13, iters 858
learning rate = 0.0002000
Epoch 13/40 | time: 429.0195 - train_acc: 56.06% - train_loss: 0.6692 - val_acc: 66.67% - val_loss: 0.5675
saving the latest model (epoch 14, total_steps 859)
loaded mean / std from cache
saving the model at the end of epoch 14, iters 924
learning rate = 0.0002000
Epoch 14/40 | time: 427.1340 - train_acc: 63.64% - train_loss: 0.6840 - val_acc: 58.33% - val_loss: 0.5709
Early Stopping: val_loss did not lower, patience 1/5
saving the latest model (epoch 15, total_steps 925)
loaded mean / std from cache
saving the model at the end of epoch 15, iters 990
learning rate = 0.0002000
Epoch 15/40 | time: 429.8101 - train_acc: 48.48% - train_loss: 0.7039 - val_acc: 66.67% - val_loss: 0.5739
Early Stopping: val_loss did not lower, patience 2/5
saving the latest model (epoch 16, total_steps 991)
loaded mean / std from cache
saving the model at the end of epoch 16, iters 1056
learning rate = 0.0002000
Epoch 16/40 | time: 428.4257 - train_acc: 66.67% - train_loss: 0.6509 - val_acc: 91.67% - val_loss: 0.4115
saving the latest model (epoch 17, total_steps 1057)
loaded mean / std from cache
saving the model at the end of epoch 17, iters 1122
learning rate = 0.0002000
Epoch 17/40 | time: 429.9375 - train_acc: 68.18% - train_loss: 0.6112 - val_acc: 75.00% - val_loss: 0.5021
Early Stopping: val_loss did not lower, patience 2/5
saving the latest model (epoch 18, total_steps 1123)
loaded mean / std from cache
saving the model at the end of epoch 18, iters 1188
learning rate = 0.0002000
Epoch 18/40 | time: 428.3463 - train_acc: 69.70% - train_loss: 0.6359 - val_acc: 83.33% - val_loss: 0.5414
Early Stopping: val_loss did not lower, patience 3/5
saving the latest model (epoch 19, total_steps 1189)
loaded mean / std from cache
saving the model at the end of epoch 19, iters 1254
learning rate = 0.0002000
Epoch 19/40 | time: 428.2695 - train_acc: 68.18% - train_loss: 0.6670 - val_acc: 83.33% - val_loss: 0.4434
saving the latest model (epoch 20, total_steps 1255)
loaded mean / std from cache
saving the model at the end of epoch 20, iters 1320
learning rate = 0.0002000
Epoch 20/40 | time: 427.1959 - train_acc: 65.15% - train_loss: 0.6422 - val_acc: 66.67% - val_loss: 0.7355
Early Stopping: val_loss did not lower, patience 3/5
saving the latest model (epoch 21, total_steps 1321)
loaded mean / std from cache
saving the model at the end of epoch 21, iters 1386
learning rate = 0.0002000
Epoch 21/40 | time: 432.3859 - train_acc: 65.15% - train_loss: 0.6016 - val_acc: 58.33% - val_loss: 0.6599
saving the latest model (epoch 22, total_steps 1387)
loaded mean / std from cache
saving the model at the end of epoch 22, iters 1452
learning rate = 0.0002000
Epoch 22/40 | time: 426.9795 - train_acc: 78.79% - train_loss: 0.5649 - val_acc: 75.00% - val_loss: 0.4271
saving the latest model (epoch 23, total_steps 1453)
loaded mean / std from cache
saving the model at the end of epoch 23, iters 1518
learning rate = 0.0002000
Epoch 23/40 | time: 428.8949 - train_acc: 81.82% - train_loss: 0.6306 - val_acc: 83.33% - val_loss: 0.4706
Early Stopping: val_loss did not lower, patience 2/5
saving the latest model (epoch 24, total_steps 1519)
loaded mean / std from cache
saving the model at the end of epoch 24, iters 1584
learning rate = 0.0002000
Epoch 24/40 | time: 426.7155 - train_acc: 68.18% - train_loss: 0.7019 - val_acc: 75.00% - val_loss: 0.5063
Early Stopping: val_loss did not lower, patience 3/5
saving the latest model (epoch 25, total_steps 1585)
loaded mean / std from cache
saving the model at the end of epoch 25, iters 1650
learning rate = 0.0002000
Epoch 25/40 | time: 425.9423 - train_acc: 66.67% - train_loss: 0.5930 - val_acc: 83.33% - val_loss: 0.4542
saving the latest model (epoch 26, total_steps 1651)
loaded mean / std from cache
saving the model at the end of epoch 26, iters 1716
learning rate = 0.0002000
Epoch 26/40 | time: 430.2418 - train_acc: 65.15% - train_loss: 0.6190 - val_acc: 83.33% - val_loss: 0.4490
saving the latest model (epoch 27, total_steps 1717)
loaded mean / std from cache
saving the model at the end of epoch 27, iters 1782
learning rate = 0.0002000
Epoch 27/40 | time: 430.6864 - train_acc: 71.21% - train_loss: 0.5729 - val_acc: 75.00% - val_loss: 0.5426
Early Stopping: val_loss did not lower, patience 2/5
saving the latest model (epoch 28, total_steps 1783)
loaded mean / std from cache
saving the model at the end of epoch 28, iters 1848
learning rate = 0.0002000
Epoch 28/40 | time: 426.9107 - train_acc: 75.76% - train_loss: 0.5518 - val_acc: 75.00% - val_loss: 0.5220
saving the latest model (epoch 29, total_steps 1849)
loaded mean / std from cache
saving the model at the end of epoch 29, iters 1914
learning rate = 0.0001818
Epoch 29/40 | time: 427.9777 - train_acc: 71.21% - train_loss: 0.5580 - val_acc: 75.00% - val_loss: 0.5655
Early Stopping: val_loss did not lower, patience 2/5
saving the latest model (epoch 30, total_steps 1915)
loaded mean / std from cache
saving the model at the end of epoch 30, iters 1980
learning rate = 0.0001636
Epoch 30/40 | time: 428.1389 - train_acc: 74.24% - train_loss: 0.5241 - val_acc: 83.33% - val_loss: 0.4122
saving the latest model (epoch 31, total_steps 1981)
loaded mean / std from cache
saving the model at the end of epoch 31, iters 2046
learning rate = 0.0001455
Epoch 31/40 | time: 426.8518 - train_acc: 66.67% - train_loss: 0.5130 - val_acc: 75.00% - val_loss: 0.4556
Early Stopping: val_loss did not lower, patience 2/5
saving the latest model (epoch 32, total_steps 2047)
loaded mean / std from cache
saving the model at the end of epoch 32, iters 2112
learning rate = 0.0001273
Epoch 32/40 | time: 428.4331 - train_acc: 78.79% - train_loss: 0.4619 - val_acc: 83.33% - val_loss: 0.3781
saving the latest model (epoch 33, total_steps 2113)
loaded mean / std from cache
saving the model at the end of epoch 33, iters 2178
learning rate = 0.0001091
Epoch 33/40 | time: 428.0595 - train_acc: 75.76% - train_loss: 0.5933 - val_acc: 83.33% - val_loss: 0.4229
Early Stopping: val_loss did not lower, patience 2/5
saving the latest model (epoch 34, total_steps 2179)
loaded mean / std from cache
saving the model at the end of epoch 34, iters 2244
learning rate = 0.0000909
Epoch 34/40 | time: 425.2841 - train_acc: 75.76% - train_loss: 0.5080 - val_acc: 83.33% - val_loss: 0.3835
saving the latest model (epoch 35, total_steps 2245)
loaded mean / std from cache
saving the model at the end of epoch 35, iters 2310
learning rate = 0.0000727
Epoch 35/40 | time: 424.6320 - train_acc: 74.24% - train_loss: 0.5195 - val_acc: 83.33% - val_loss: 0.4916
Early Stopping: val_loss did not lower, patience 2/5
saving the latest model (epoch 36, total_steps 2311)
loaded mean / std from cache
saving the model at the end of epoch 36, iters 2376
learning rate = 0.0000545
Epoch 36/40 | time: 425.5662 - train_acc: 75.76% - train_loss: 0.4382 - val_acc: 66.67% - val_loss: 0.4683
saving the latest model (epoch 37, total_steps 2377)
loaded mean / std from cache
saving the model at the end of epoch 37, iters 2442
learning rate = 0.0000364
Epoch 37/40 | time: 427.0409 - train_acc: 80.30% - train_loss: 0.4408 - val_acc: 75.00% - val_loss: 0.4588
saving the latest model (epoch 38, total_steps 2443)
loaded mean / std from cache
saving the model at the end of epoch 38, iters 2508
learning rate = 0.0000182
Epoch 38/40 | time: 425.1382 - train_acc: 83.33% - train_loss: 0.4473 - val_acc: 83.33% - val_loss: 0.4975
Early Stopping: val_loss did not lower, patience 1/5
saving the latest model (epoch 39, total_steps 2509)
loaded mean / std from cache
saving the model at the end of epoch 39, iters 2574
learning rate = 0.0000000
Epoch 39/40 | time: 434.2555 - train_acc: 83.33% - train_loss: 0.4407 - val_acc: 75.00% - val_loss: 0.4976
Early Stopping: val_loss did not lower, patience 2/5
saving the latest model (epoch 40, total_steps 2575)
loaded mean / std from cache
saving the model at the end of epoch 40, iters 2640
learning rate = -0.0000182
Epoch 40/40 | time: 426.6999 - train_acc: 81.82% - train_loss: 0.4249 - val_acc: 75.00% - val_loss: 0.5953
Early Stopping: val_loss did not lower, patience 3/5
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/Nodule-98-30K-GS-2022_07_07__16_51_01/latest_net.pth
Mesh         Prediction    Actual
-----------  ------------  --------
110-Izq.obj  nonodule      nodule
117-Izq.obj  nonodule      nodule
161-Izq.obj  nodule        nodule
216-Izq.obj  nonodule      nodule
229-Izq.obj  nonodule      nodule
346-Izq.obj  nonodule      nodule
456-Izq.obj  nonodule      nodule
475-Izq.obj  nodule        nodule
564-Izq.obj  nonodule      nodule
95-Izq.obj   nonodule      nodule
1-Izq.obj    nonodule      nonodule
15-Izq.obj   nodule        nonodule
19-Izq.obj   nonodule      nonodule
21-Izq.obj   nodule        nonodule
22-Izq.obj   nonodule      nonodule
23-Izq.obj   nonodule      nonodule
35-Izq.obj   nonodule      nonodule
43-Izq.obj   nonodule      nonodule
50-Izq.obj   nonodule      nonodule
7-Izq.obj    nonodule      nonodule
Reporte de clasificación:
              precision    recall  f1-score   support

      nodule       0.50      0.20      0.29        10
    nonodule       0.50      0.80      0.62        10

    accuracy                           0.50        20
   macro avg       0.50      0.50      0.45        20
weighted avg       0.50      0.50      0.45        20

epoch: -1, TEST ACC: [50.00%], LOSS: 0.688

------------ Options -------------
amsgrad: False
arch: mconvnet
batch_size: 1
beta1: 0.9
checkpoints_dir: ./checkpoints
continue_train: False
csv: True
dataroot: ./data/datasets/Nodule-98-30K
dataset_mode: classification
dropout: [0.5, 0.25, 0.125]
epoch_count: 1
export_folder: 
fc_n: [1024, 512, 128]
flip_edges: 0.4
gpu_ids: [0]
init_gain: 0.02
init_type: kaiming
is_train: True
lr: 0.0002
lr_decay_iters: 50
lr_policy: lambda
max_dataset_size: inf
name: Nodule-98-30K-GS-2022_07_07__21_38_48
ncf: [32, 64, 256, 256]
ninput_edges: 30000
niter: 30
niter_decay: 10
no_vis: False
norm: batch
num_aug: 40
num_groups: 16
num_threads: 2
optimizer: rmsprop
phase: train
plus: False
pool_res: [20000, 15000, 10000, 5000]
print_freq: 9999
resblocks: 0
run_test_freq: 9999
save_epoch_freq: 1
save_latest_freq: 250
scale_verts: True
seed: 16
serial_batches: False
slide_verts: 0.4
validation: True
verbose_plot: False
verbose_train: True
which_epoch: latest
-------------- End ----------------
loaded mean / std from cache
#training meshes = 66
---------- Network initialized -------------
[Network] Total number of parameters : 1.276 M
-----------------------------------------------
saving the latest model (epoch 1, total_steps 1)
!WARNING! Queue below 100 edges on mesh 407-Izq.obj
!WARNING! Queue below 100 edges on mesh 28-Izq.obj
Traceback (most recent call last):
  File "./networks/MeshCNNPlus/development/meshcnn/train.py", line 104, in <module>
    model.optimize_parameters()
  File "/mnt/homeGPU/vlugli/tfg/networks/MeshCNNPlus/development/meshcnn/models/mesh_classifier.py", line 84, in optimize_parameters
    out = self.forward()
  File "/mnt/homeGPU/vlugli/tfg/networks/MeshCNNPlus/development/meshcnn/models/mesh_classifier.py", line 75, in forward
    out = self.net(self.edge_features, self.mesh)
  File "/mnt/homeGPU/vlugli/condaEnvs/meshcnnplus/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/mnt/homeGPU/vlugli/condaEnvs/meshcnnplus/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py", line 159, in forward
    return self.module(*inputs[0], **kwargs[0])
  File "/mnt/homeGPU/vlugli/condaEnvs/meshcnnplus/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/mnt/homeGPU/vlugli/tfg/networks/MeshCNNPlus/development/meshcnn/models/networks.py", line 165, in forward
    x = getattr(self, 'pool{}'.format(i))(x, mesh)
  File "/mnt/homeGPU/vlugli/tfg/networks/MeshCNNPlus/development/meshcnn/models/layers/mesh_pool.py", line 21, in __call__
    return self.forward(fe, meshes)
  File "/mnt/homeGPU/vlugli/tfg/networks/MeshCNNPlus/development/meshcnn/models/layers/mesh_pool.py", line 34, in forward
    self.__pool_main(mesh_index)
  File "/mnt/homeGPU/vlugli/tfg/networks/MeshCNNPlus/development/meshcnn/models/layers/mesh_pool.py", line 51, in __pool_main
    value, edge_id = heappop(queue)
IndexError: index out of range
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/Nodule-98-30K-GS-2022_07_07__21_38_48/latest_net.pth
/mnt/homeGPU/vlugli/condaEnvs/meshcnnplus/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/mnt/homeGPU/vlugli/condaEnvs/meshcnnplus/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/mnt/homeGPU/vlugli/condaEnvs/meshcnnplus/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Mesh         Prediction    Actual
-----------  ------------  --------
110-Izq.obj  nodule        nodule
117-Izq.obj  nodule        nodule
161-Izq.obj  nodule        nodule
216-Izq.obj  nodule        nodule
229-Izq.obj  nodule        nodule
346-Izq.obj  nodule        nodule
456-Izq.obj  nodule        nodule
475-Izq.obj  nodule        nodule
564-Izq.obj  nodule        nodule
95-Izq.obj   nodule        nodule
1-Izq.obj    nodule        nonodule
15-Izq.obj   nodule        nonodule
19-Izq.obj   nodule        nonodule
21-Izq.obj   nodule        nonodule
22-Izq.obj   nodule        nonodule
23-Izq.obj   nodule        nonodule
35-Izq.obj   nodule        nonodule
43-Izq.obj   nodule        nonodule
50-Izq.obj   nodule        nonodule
7-Izq.obj    nodule        nonodule
Reporte de clasificación:
              precision    recall  f1-score   support

      nodule       0.50      1.00      0.67        10
    nonodule       0.00      0.00      0.00        10

    accuracy                           0.50        20
   macro avg       0.25      0.50      0.33        20
weighted avg       0.25      0.50      0.33        20

epoch: -1, TEST ACC: [50.00%], LOSS: 66.983

------------ Options -------------
amsgrad: False
arch: mconvnet
batch_size: 1
beta1: 0.9
checkpoints_dir: ./checkpoints
continue_train: False
csv: True
dataroot: ./data/datasets/Nodule-98-30K
dataset_mode: classification
dropout: [0.25, 0.25, 0.25]
epoch_count: 1
export_folder: 
fc_n: [2042, 512, 128]
flip_edges: 0.2
gpu_ids: [0]
init_gain: 0.02
init_type: kaiming
is_train: True
lr: 0.0002
lr_decay_iters: 50
lr_policy: lambda
max_dataset_size: inf
name: Nodule-98-30K-GS-2022_07_07__21_42_48
ncf: [256, 128, 64, 32]
ninput_edges: 30000
niter: 30
niter_decay: 10
no_vis: False
norm: batch
num_aug: 20
num_groups: 16
num_threads: 2
optimizer: rmsprop
phase: train
plus: False
pool_res: [20000, 15000, 10000, 5000]
print_freq: 9999
resblocks: 0
run_test_freq: 9999
save_epoch_freq: 1
save_latest_freq: 250
scale_verts: False
seed: 16
serial_batches: False
slide_verts: 0.2
validation: True
verbose_plot: False
verbose_train: True
which_epoch: latest
-------------- End ----------------
loaded mean / std from cache
#training meshes = 66
---------- Network initialized -------------
[Network] Total number of parameters : 1.402 M
-----------------------------------------------
saving the latest model (epoch 1, total_steps 1)
loaded mean / std from cache
saving the model at the end of epoch 1, iters 66
learning rate = 0.0002000
Epoch 1/40 | time: 440.0597 - train_acc: 56.06% - train_loss: 1.0673 - val_acc: 58.33% - val_loss: 0.7088
saving the latest model (epoch 2, total_steps 67)
loaded mean / std from cache
saving the model at the end of epoch 2, iters 132
learning rate = 0.0002000
Epoch 2/40 | time: 437.7028 - train_acc: 59.09% - train_loss: 0.7966 - val_acc: 41.67% - val_loss: 0.7851
Early Stopping: val_loss did not lower, patience 1/5
saving the latest model (epoch 3, total_steps 133)
loaded mean / std from cache
saving the model at the end of epoch 3, iters 198
learning rate = 0.0002000
Epoch 3/40 | time: 435.6171 - train_acc: 63.64% - train_loss: 0.7754 - val_acc: 66.67% - val_loss: 0.6322
saving the latest model (epoch 4, total_steps 199)
loaded mean / std from cache
saving the model at the end of epoch 4, iters 264
learning rate = 0.0002000
Epoch 4/40 | time: 437.1473 - train_acc: 60.61% - train_loss: 0.7100 - val_acc: 58.33% - val_loss: 0.6923
Early Stopping: val_loss did not lower, patience 1/5
saving the latest model (epoch 5, total_steps 265)
loaded mean / std from cache
saving the model at the end of epoch 5, iters 330
learning rate = 0.0002000
Epoch 5/40 | time: 436.1783 - train_acc: 57.58% - train_loss: 0.7297 - val_acc: 50.00% - val_loss: 0.7308
Early Stopping: val_loss did not lower, patience 2/5
saving the latest model (epoch 6, total_steps 331)
loaded mean / std from cache
saving the model at the end of epoch 6, iters 396
learning rate = 0.0002000
Epoch 6/40 | time: 437.5243 - train_acc: 51.52% - train_loss: 0.6782 - val_acc: 66.67% - val_loss: 0.5713
saving the latest model (epoch 7, total_steps 397)
loaded mean / std from cache
saving the model at the end of epoch 7, iters 462
learning rate = 0.0002000
Epoch 7/40 | time: 432.9491 - train_acc: 69.70% - train_loss: 0.7026 - val_acc: 83.33% - val_loss: 0.4616
saving the latest model (epoch 8, total_steps 463)
loaded mean / std from cache
saving the model at the end of epoch 8, iters 528
learning rate = 0.0002000
Epoch 8/40 | time: 431.7705 - train_acc: 59.09% - train_loss: 0.6808 - val_acc: 66.67% - val_loss: 0.5667
Early Stopping: val_loss did not lower, patience 1/5
saving the latest model (epoch 9, total_steps 529)
loaded mean / std from cache
saving the model at the end of epoch 9, iters 594
learning rate = 0.0002000
Epoch 9/40 | time: 433.2174 - train_acc: 60.61% - train_loss: 0.6933 - val_acc: 58.33% - val_loss: 0.6461
Early Stopping: val_loss did not lower, patience 2/5
saving the latest model (epoch 10, total_steps 595)
loaded mean / std from cache
saving the model at the end of epoch 10, iters 660
learning rate = 0.0002000
Epoch 10/40 | time: 432.9346 - train_acc: 56.06% - train_loss: 0.5721 - val_acc: 50.00% - val_loss: 0.7786
Early Stopping: val_loss did not lower, patience 3/5
saving the latest model (epoch 11, total_steps 661)
loaded mean / std from cache
saving the model at the end of epoch 11, iters 726
learning rate = 0.0002000
Epoch 11/40 | time: 430.8898 - train_acc: 72.73% - train_loss: 0.6196 - val_acc: 58.33% - val_loss: 0.5787
saving the latest model (epoch 12, total_steps 727)
loaded mean / std from cache
saving the model at the end of epoch 12, iters 792
learning rate = 0.0002000
Epoch 12/40 | time: 428.9722 - train_acc: 71.21% - train_loss: 0.6004 - val_acc: 58.33% - val_loss: 0.5726
saving the latest model (epoch 13, total_steps 793)
loaded mean / std from cache
saving the model at the end of epoch 13, iters 858
learning rate = 0.0002000
Epoch 13/40 | time: 430.5935 - train_acc: 56.06% - train_loss: 0.6568 - val_acc: 58.33% - val_loss: 0.7243
Early Stopping: val_loss did not lower, patience 2/5
saving the latest model (epoch 14, total_steps 859)
loaded mean / std from cache
saving the model at the end of epoch 14, iters 924
learning rate = 0.0002000
Epoch 14/40 | time: 429.8986 - train_acc: 75.76% - train_loss: 0.5725 - val_acc: 58.33% - val_loss: 0.5803
saving the latest model (epoch 15, total_steps 925)
loaded mean / std from cache
saving the model at the end of epoch 15, iters 990
learning rate = 0.0002000
Epoch 15/40 | time: 434.1970 - train_acc: 62.12% - train_loss: 0.6569 - val_acc: 66.67% - val_loss: 0.6487
Early Stopping: val_loss did not lower, patience 2/5
saving the latest model (epoch 16, total_steps 991)
loaded mean / std from cache
saving the model at the end of epoch 16, iters 1056
learning rate = 0.0002000
Epoch 16/40 | time: 432.0826 - train_acc: 62.12% - train_loss: 0.6452 - val_acc: 91.67% - val_loss: 0.4880
saving the latest model (epoch 17, total_steps 1057)
loaded mean / std from cache
saving the model at the end of epoch 17, iters 1122
learning rate = 0.0002000
Epoch 17/40 | time: 429.3814 - train_acc: 75.76% - train_loss: 0.6153 - val_acc: 83.33% - val_loss: 0.4266
saving the latest model (epoch 18, total_steps 1123)
loaded mean / std from cache
saving the model at the end of epoch 18, iters 1188
learning rate = 0.0002000
Epoch 18/40 | time: 427.7792 - train_acc: 66.67% - train_loss: 0.5726 - val_acc: 66.67% - val_loss: 0.5283
Early Stopping: val_loss did not lower, patience 1/5
saving the latest model (epoch 19, total_steps 1189)
loaded mean / std from cache
saving the model at the end of epoch 19, iters 1254
learning rate = 0.0002000
Epoch 19/40 | time: 429.1417 - train_acc: 78.79% - train_loss: 0.5834 - val_acc: 66.67% - val_loss: 0.5311
Early Stopping: val_loss did not lower, patience 2/5
saving the latest model (epoch 20, total_steps 1255)
loaded mean / std from cache
saving the model at the end of epoch 20, iters 1320
learning rate = 0.0002000
Epoch 20/40 | time: 429.9876 - train_acc: 71.21% - train_loss: 0.5087 - val_acc: 83.33% - val_loss: 0.3964
saving the latest model (epoch 21, total_steps 1321)
loaded mean / std from cache
saving the model at the end of epoch 21, iters 1386
learning rate = 0.0002000
Epoch 21/40 | time: 429.2681 - train_acc: 75.76% - train_loss: 0.6580 - val_acc: 91.67% - val_loss: 0.4962
Early Stopping: val_loss did not lower, patience 2/5
saving the latest model (epoch 22, total_steps 1387)
loaded mean / std from cache
saving the model at the end of epoch 22, iters 1452
learning rate = 0.0002000
Epoch 22/40 | time: 429.6824 - train_acc: 68.18% - train_loss: 0.5962 - val_acc: 66.67% - val_loss: 0.4420
saving the latest model (epoch 23, total_steps 1453)
loaded mean / std from cache
saving the model at the end of epoch 23, iters 1518
learning rate = 0.0002000
Epoch 23/40 | time: 429.5894 - train_acc: 65.15% - train_loss: 0.4855 - val_acc: 83.33% - val_loss: 0.4034
saving the latest model (epoch 24, total_steps 1519)
loaded mean / std from cache
saving the model at the end of epoch 24, iters 1584
learning rate = 0.0002000
Epoch 24/40 | time: 429.3523 - train_acc: 68.18% - train_loss: 0.5545 - val_acc: 75.00% - val_loss: 0.4561
Early Stopping: val_loss did not lower, patience 1/5
saving the latest model (epoch 25, total_steps 1585)
loaded mean / std from cache
saving the model at the end of epoch 25, iters 1650
learning rate = 0.0002000
Epoch 25/40 | time: 428.9009 - train_acc: 63.64% - train_loss: 0.5655 - val_acc: 75.00% - val_loss: 0.6022
Early Stopping: val_loss did not lower, patience 2/5
saving the latest model (epoch 26, total_steps 1651)
loaded mean / std from cache
saving the model at the end of epoch 26, iters 1716
learning rate = 0.0002000
Epoch 26/40 | time: 429.0050 - train_acc: 69.70% - train_loss: 0.5435 - val_acc: 83.33% - val_loss: 0.5296
saving the latest model (epoch 27, total_steps 1717)
loaded mean / std from cache
saving the model at the end of epoch 27, iters 1782
learning rate = 0.0002000
Epoch 27/40 | time: 429.9247 - train_acc: 69.70% - train_loss: 0.6049 - val_acc: 75.00% - val_loss: 0.5457
Early Stopping: val_loss did not lower, patience 2/5
saving the latest model (epoch 28, total_steps 1783)
loaded mean / std from cache
saving the model at the end of epoch 28, iters 1848
learning rate = 0.0002000
Epoch 28/40 | time: 428.1186 - train_acc: 75.76% - train_loss: 0.5640 - val_acc: 83.33% - val_loss: 0.3728
saving the latest model (epoch 29, total_steps 1849)
loaded mean / std from cache
saving the model at the end of epoch 29, iters 1914
learning rate = 0.0001818
Epoch 29/40 | time: 428.5200 - train_acc: 78.79% - train_loss: 0.5880 - val_acc: 91.67% - val_loss: 0.4856
Early Stopping: val_loss did not lower, patience 2/5
saving the latest model (epoch 30, total_steps 1915)
loaded mean / std from cache
saving the model at the end of epoch 30, iters 1980
learning rate = 0.0001636
Epoch 30/40 | time: 428.0664 - train_acc: 69.70% - train_loss: 0.4634 - val_acc: 83.33% - val_loss: 0.4370
saving the latest model (epoch 31, total_steps 1981)
loaded mean / std from cache
saving the model at the end of epoch 31, iters 2046
learning rate = 0.0001455
Epoch 31/40 | time: 427.0901 - train_acc: 83.33% - train_loss: 0.4758 - val_acc: 91.67% - val_loss: 0.2637
saving the latest model (epoch 32, total_steps 2047)
loaded mean / std from cache
saving the model at the end of epoch 32, iters 2112
learning rate = 0.0001273
Epoch 32/40 | time: 428.7758 - train_acc: 81.82% - train_loss: 0.5532 - val_acc: 75.00% - val_loss: 0.3763
Early Stopping: val_loss did not lower, patience 1/5
saving the latest model (epoch 33, total_steps 2113)
loaded mean / std from cache
saving the model at the end of epoch 33, iters 2178
learning rate = 0.0001091
Epoch 33/40 | time: 428.7960 - train_acc: 69.70% - train_loss: 0.3879 - val_acc: 75.00% - val_loss: 0.3505
saving the latest model (epoch 34, total_steps 2179)
loaded mean / std from cache
saving the model at the end of epoch 34, iters 2244
learning rate = 0.0000909
Epoch 34/40 | time: 428.6165 - train_acc: 81.82% - train_loss: 0.4749 - val_acc: 83.33% - val_loss: 0.2819
saving the latest model (epoch 35, total_steps 2245)
loaded mean / std from cache
saving the model at the end of epoch 35, iters 2310
learning rate = 0.0000727
Epoch 35/40 | time: 431.2486 - train_acc: 81.82% - train_loss: 0.4290 - val_acc: 83.33% - val_loss: 0.7448
Early Stopping: val_loss did not lower, patience 1/5
saving the latest model (epoch 36, total_steps 2311)
loaded mean / std from cache
saving the model at the end of epoch 36, iters 2376
learning rate = 0.0000545
Epoch 36/40 | time: 433.8786 - train_acc: 81.82% - train_loss: 0.3662 - val_acc: 83.33% - val_loss: 0.2754
saving the latest model (epoch 37, total_steps 2377)
loaded mean / std from cache
saving the model at the end of epoch 37, iters 2442
learning rate = 0.0000364
Epoch 37/40 | time: 430.8731 - train_acc: 83.33% - train_loss: 0.4584 - val_acc: 83.33% - val_loss: 0.3043
Early Stopping: val_loss did not lower, patience 1/5
saving the latest model (epoch 38, total_steps 2443)
loaded mean / std from cache
saving the model at the end of epoch 38, iters 2508
learning rate = 0.0000182
Epoch 38/40 | time: 429.9275 - train_acc: 93.94% - train_loss: 0.3267 - val_acc: 75.00% - val_loss: 0.4561
Early Stopping: val_loss did not lower, patience 2/5
saving the latest model (epoch 39, total_steps 2509)
loaded mean / std from cache
saving the model at the end of epoch 39, iters 2574
learning rate = 0.0000000
Epoch 39/40 | time: 437.2193 - train_acc: 89.39% - train_loss: 0.2684 - val_acc: 75.00% - val_loss: 0.5740
Early Stopping: val_loss did not lower, patience 3/5
saving the latest model (epoch 40, total_steps 2575)
loaded mean / std from cache
saving the model at the end of epoch 40, iters 2640
learning rate = -0.0000182
Epoch 40/40 | time: 427.3627 - train_acc: 90.91% - train_loss: 0.2816 - val_acc: 83.33% - val_loss: 0.3894
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/Nodule-98-30K-GS-2022_07_07__21_42_48/latest_net.pth
Mesh         Prediction    Actual
-----------  ------------  --------
110-Izq.obj  nonodule      nodule
117-Izq.obj  nonodule      nodule
161-Izq.obj  nodule        nodule
216-Izq.obj  nonodule      nodule
229-Izq.obj  nonodule      nodule
346-Izq.obj  nonodule      nodule
456-Izq.obj  nonodule      nodule
475-Izq.obj  nodule        nodule
564-Izq.obj  nonodule      nodule
95-Izq.obj   nonodule      nodule
1-Izq.obj    nonodule      nonodule
15-Izq.obj   nonodule      nonodule
19-Izq.obj   nonodule      nonodule
21-Izq.obj   nodule        nonodule
22-Izq.obj   nonodule      nonodule
23-Izq.obj   nonodule      nonodule
35-Izq.obj   nonodule      nonodule
43-Izq.obj   nonodule      nonodule
50-Izq.obj   nonodule      nonodule
7-Izq.obj    nonodule      nonodule
Reporte de clasificación:
              precision    recall  f1-score   support

      nodule       0.67      0.20      0.31        10
    nonodule       0.53      0.90      0.67        10

    accuracy                           0.55        20
   macro avg       0.60      0.55      0.49        20
weighted avg       0.60      0.55      0.49        20

epoch: -1, TEST ACC: [55.00%], LOSS: 0.744

------------ Options -------------
amsgrad: False
arch: mconvnet
batch_size: 1
beta1: 0.9
checkpoints_dir: ./checkpoints
continue_train: False
csv: True
dataroot: ./data/datasets/Nodule-98-30K
dataset_mode: classification
dropout: [0.25, 0.25, 0.25]
epoch_count: 1
export_folder: 
fc_n: [2042, 512, 128]
flip_edges: 0.4
gpu_ids: [0]
init_gain: 0.02
init_type: kaiming
is_train: True
lr: 0.0002
lr_decay_iters: 50
lr_policy: lambda
max_dataset_size: inf
name: Nodule-98-30K-GS-2022_07_08__02_32_11
ncf: [256, 128, 64, 32]
ninput_edges: 30000
niter: 30
niter_decay: 10
no_vis: False
norm: batch
num_aug: 40
num_groups: 16
num_threads: 2
optimizer: rmsprop
phase: train
plus: False
pool_res: [20000, 15000, 10000, 5000]
print_freq: 9999
resblocks: 0
run_test_freq: 9999
save_epoch_freq: 1
save_latest_freq: 250
scale_verts: True
seed: 16
serial_batches: False
slide_verts: 0.4
validation: True
verbose_plot: False
verbose_train: True
which_epoch: latest
-------------- End ----------------
loaded mean / std from cache
#training meshes = 66
---------- Network initialized -------------
[Network] Total number of parameters : 1.402 M
-----------------------------------------------
saving the latest model (epoch 1, total_steps 1)
!WARNING! Queue below 100 edges on mesh 218-Izq.obj
Traceback (most recent call last):
  File "./networks/MeshCNNPlus/development/meshcnn/train.py", line 104, in <module>
    model.optimize_parameters()
  File "/mnt/homeGPU/vlugli/tfg/networks/MeshCNNPlus/development/meshcnn/models/mesh_classifier.py", line 84, in optimize_parameters
    out = self.forward()
  File "/mnt/homeGPU/vlugli/tfg/networks/MeshCNNPlus/development/meshcnn/models/mesh_classifier.py", line 75, in forward
    out = self.net(self.edge_features, self.mesh)
  File "/mnt/homeGPU/vlugli/condaEnvs/meshcnnplus/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/mnt/homeGPU/vlugli/condaEnvs/meshcnnplus/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py", line 159, in forward
    return self.module(*inputs[0], **kwargs[0])
  File "/mnt/homeGPU/vlugli/condaEnvs/meshcnnplus/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/mnt/homeGPU/vlugli/tfg/networks/MeshCNNPlus/development/meshcnn/models/networks.py", line 165, in forward
    x = getattr(self, 'pool{}'.format(i))(x, mesh)
  File "/mnt/homeGPU/vlugli/tfg/networks/MeshCNNPlus/development/meshcnn/models/layers/mesh_pool.py", line 21, in __call__
    return self.forward(fe, meshes)
  File "/mnt/homeGPU/vlugli/tfg/networks/MeshCNNPlus/development/meshcnn/models/layers/mesh_pool.py", line 34, in forward
    self.__pool_main(mesh_index)
  File "/mnt/homeGPU/vlugli/tfg/networks/MeshCNNPlus/development/meshcnn/models/layers/mesh_pool.py", line 51, in __pool_main
    value, edge_id = heappop(queue)
IndexError: index out of range
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/Nodule-98-30K-GS-2022_07_08__02_32_11/latest_net.pth
/mnt/homeGPU/vlugli/condaEnvs/meshcnnplus/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/mnt/homeGPU/vlugli/condaEnvs/meshcnnplus/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/mnt/homeGPU/vlugli/condaEnvs/meshcnnplus/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Mesh         Prediction    Actual
-----------  ------------  --------
110-Izq.obj  nonodule      nodule
117-Izq.obj  nonodule      nodule
161-Izq.obj  nonodule      nodule
216-Izq.obj  nonodule      nodule
229-Izq.obj  nonodule      nodule
346-Izq.obj  nonodule      nodule
456-Izq.obj  nonodule      nodule
475-Izq.obj  nonodule      nodule
564-Izq.obj  nonodule      nodule
95-Izq.obj   nonodule      nodule
1-Izq.obj    nonodule      nonodule
15-Izq.obj   nonodule      nonodule
19-Izq.obj   nonodule      nonodule
21-Izq.obj   nonodule      nonodule
22-Izq.obj   nonodule      nonodule
23-Izq.obj   nonodule      nonodule
35-Izq.obj   nonodule      nonodule
43-Izq.obj   nonodule      nonodule
50-Izq.obj   nonodule      nonodule
7-Izq.obj    nonodule      nonodule
Reporte de clasificación:
              precision    recall  f1-score   support

      nodule       0.00      0.00      0.00        10
    nonodule       0.50      1.00      0.67        10

    accuracy                           0.50        20
   macro avg       0.25      0.50      0.33        20
weighted avg       0.25      0.50      0.33        20

epoch: -1, TEST ACC: [50.00%], LOSS: 101.171

------------ Options -------------
amsgrad: False
arch: mconvnet
batch_size: 1
beta1: 0.9
checkpoints_dir: ./checkpoints
continue_train: False
csv: True
dataroot: ./data/datasets/Nodule-98-30K
dataset_mode: classification
dropout: [0.5, 0.25, 0.125]
epoch_count: 1
export_folder: 
fc_n: [1024, 512, 128]
flip_edges: 0.2
gpu_ids: [0]
init_gain: 0.02
init_type: kaiming
is_train: True
lr: 0.0002
lr_decay_iters: 50
lr_policy: lambda
max_dataset_size: inf
name: Nodule-98-30K-GS-2022_07_08__02_34_24
ncf: [256, 128, 64, 32]
ninput_edges: 30000
niter: 30
niter_decay: 10
no_vis: False
norm: batch
num_aug: 20
num_groups: 16
num_threads: 2
optimizer: rmsprop
phase: train
plus: False
pool_res: [20000, 15000, 10000, 5000]
print_freq: 9999
resblocks: 0
run_test_freq: 9999
save_epoch_freq: 1
save_latest_freq: 250
scale_verts: False
seed: 16
serial_batches: False
slide_verts: 0.2
validation: True
verbose_plot: False
verbose_train: True
which_epoch: latest
-------------- End ----------------
loaded mean / std from cache
#training meshes = 66
---------- Network initialized -------------
[Network] Total number of parameters : 0.847 M
-----------------------------------------------
saving the latest model (epoch 1, total_steps 1)
loaded mean / std from cache
saving the model at the end of epoch 1, iters 66
learning rate = 0.0002000
Epoch 1/40 | time: 442.6360 - train_acc: 43.94% - train_loss: 0.9287 - val_acc: 83.33% - val_loss: 0.5711
saving the latest model (epoch 2, total_steps 67)
loaded mean / std from cache
saving the model at the end of epoch 2, iters 132
learning rate = 0.0002000
Epoch 2/40 | time: 442.6987 - train_acc: 57.58% - train_loss: 0.7387 - val_acc: 41.67% - val_loss: 0.8265
Early Stopping: val_loss did not lower, patience 1/5
saving the latest model (epoch 3, total_steps 133)
loaded mean / std from cache
saving the model at the end of epoch 3, iters 198
learning rate = 0.0002000
Epoch 3/40 | time: 442.2391 - train_acc: 50.00% - train_loss: 0.6795 - val_acc: 25.00% - val_loss: 0.8442
Early Stopping: val_loss did not lower, patience 2/5
saving the latest model (epoch 4, total_steps 199)
loaded mean / std from cache
saving the model at the end of epoch 4, iters 264
learning rate = 0.0002000
Epoch 4/40 | time: 440.3519 - train_acc: 56.06% - train_loss: 0.7448 - val_acc: 58.33% - val_loss: 0.6180
saving the latest model (epoch 5, total_steps 265)
loaded mean / std from cache
saving the model at the end of epoch 5, iters 330
learning rate = 0.0002000
Epoch 5/40 | time: 440.4278 - train_acc: 62.12% - train_loss: 0.7222 - val_acc: 66.67% - val_loss: 0.5841
saving the latest model (epoch 6, total_steps 331)
loaded mean / std from cache
saving the model at the end of epoch 6, iters 396
learning rate = 0.0002000
Epoch 6/40 | time: 441.3573 - train_acc: 54.55% - train_loss: 0.6439 - val_acc: 91.67% - val_loss: 0.5556
saving the latest model (epoch 7, total_steps 397)
loaded mean / std from cache
saving the model at the end of epoch 7, iters 462
learning rate = 0.0002000
Epoch 7/40 | time: 439.2263 - train_acc: 69.70% - train_loss: 0.6679 - val_acc: 50.00% - val_loss: 0.6404
Early Stopping: val_loss did not lower, patience 1/5
saving the latest model (epoch 8, total_steps 463)
loaded mean / std from cache
saving the model at the end of epoch 8, iters 528
learning rate = 0.0002000
Epoch 8/40 | time: 439.0916 - train_acc: 65.15% - train_loss: 0.6589 - val_acc: 83.33% - val_loss: 0.4700
saving the latest model (epoch 9, total_steps 529)
loaded mean / std from cache
saving the model at the end of epoch 9, iters 594
learning rate = 0.0002000
Epoch 9/40 | time: 439.7697 - train_acc: 65.15% - train_loss: 0.6380 - val_acc: 58.33% - val_loss: 0.5417
Early Stopping: val_loss did not lower, patience 1/5
saving the latest model (epoch 10, total_steps 595)
loaded mean / std from cache
saving the model at the end of epoch 10, iters 660
learning rate = 0.0002000
Epoch 10/40 | time: 438.7754 - train_acc: 71.21% - train_loss: 0.6751 - val_acc: 58.33% - val_loss: 0.5323
saving the latest model (epoch 11, total_steps 661)
loaded mean / std from cache
saving the model at the end of epoch 11, iters 726
learning rate = 0.0002000
Epoch 11/40 | time: 438.1234 - train_acc: 71.21% - train_loss: 0.6559 - val_acc: 83.33% - val_loss: 0.5436
Early Stopping: val_loss did not lower, patience 1/5
saving the latest model (epoch 12, total_steps 727)
loaded mean / std from cache
saving the model at the end of epoch 12, iters 792
learning rate = 0.0002000
Epoch 12/40 | time: 435.1736 - train_acc: 69.70% - train_loss: 0.6083 - val_acc: 75.00% - val_loss: 0.5410
saving the latest model (epoch 13, total_steps 793)
loaded mean / std from cache
saving the model at the end of epoch 13, iters 858
learning rate = 0.0002000
Epoch 13/40 | time: 434.7457 - train_acc: 69.70% - train_loss: 0.5744 - val_acc: 75.00% - val_loss: 0.5434
Early Stopping: val_loss did not lower, patience 1/5
saving the latest model (epoch 14, total_steps 859)
loaded mean / std from cache
saving the model at the end of epoch 14, iters 924
learning rate = 0.0002000
Epoch 14/40 | time: 437.0684 - train_acc: 77.27% - train_loss: 0.5958 - val_acc: 50.00% - val_loss: 0.6524
Early Stopping: val_loss did not lower, patience 2/5
saving the latest model (epoch 15, total_steps 925)
loaded mean / std from cache
saving the model at the end of epoch 15, iters 990
learning rate = 0.0002000
Epoch 15/40 | time: 440.2286 - train_acc: 75.76% - train_loss: 0.6176 - val_acc: 58.33% - val_loss: 0.6459
saving the latest model (epoch 16, total_steps 991)
loaded mean / std from cache
saving the model at the end of epoch 16, iters 1056
learning rate = 0.0002000
Epoch 16/40 | time: 438.7724 - train_acc: 74.24% - train_loss: 0.5944 - val_acc: 58.33% - val_loss: 0.6245
saving the latest model (epoch 17, total_steps 1057)
loaded mean / std from cache
saving the model at the end of epoch 17, iters 1122
learning rate = 0.0002000
Epoch 17/40 | time: 437.3717 - train_acc: 74.24% - train_loss: 0.5924 - val_acc: 75.00% - val_loss: 0.6834
Early Stopping: val_loss did not lower, patience 1/5
saving the latest model (epoch 18, total_steps 1123)
loaded mean / std from cache
saving the model at the end of epoch 18, iters 1188
learning rate = 0.0002000
Epoch 18/40 | time: 438.0695 - train_acc: 80.30% - train_loss: 0.6043 - val_acc: 75.00% - val_loss: 0.4760
saving the latest model (epoch 19, total_steps 1189)
loaded mean / std from cache
saving the model at the end of epoch 19, iters 1254
learning rate = 0.0002000
Epoch 19/40 | time: 437.6441 - train_acc: 80.30% - train_loss: 0.5481 - val_acc: 50.00% - val_loss: 0.6664
Early Stopping: val_loss did not lower, patience 1/5
saving the latest model (epoch 20, total_steps 1255)
loaded mean / std from cache
saving the model at the end of epoch 20, iters 1320
learning rate = 0.0002000
Epoch 20/40 | time: 436.7530 - train_acc: 77.27% - train_loss: 0.4632 - val_acc: 83.33% - val_loss: 0.5233
saving the latest model (epoch 21, total_steps 1321)
loaded mean / std from cache
saving the model at the end of epoch 21, iters 1386
learning rate = 0.0002000
Epoch 21/40 | time: 434.1947 - train_acc: 74.24% - train_loss: 0.5460 - val_acc: 58.33% - val_loss: 0.5613
Early Stopping: val_loss did not lower, patience 1/5
saving the latest model (epoch 22, total_steps 1387)
loaded mean / std from cache
saving the model at the end of epoch 22, iters 1452
learning rate = 0.0002000
Epoch 22/40 | time: 434.2684 - train_acc: 77.27% - train_loss: 0.4820 - val_acc: 66.67% - val_loss: 0.6741
Early Stopping: val_loss did not lower, patience 2/5
saving the latest model (epoch 23, total_steps 1453)
loaded mean / std from cache
saving the model at the end of epoch 23, iters 1518
learning rate = 0.0002000
Epoch 23/40 | time: 435.4168 - train_acc: 78.79% - train_loss: 0.5239 - val_acc: 75.00% - val_loss: 0.4983
saving the latest model (epoch 24, total_steps 1519)
loaded mean / std from cache
saving the model at the end of epoch 24, iters 1584
learning rate = 0.0002000
Epoch 24/40 | time: 436.0203 - train_acc: 65.15% - train_loss: 0.5263 - val_acc: 58.33% - val_loss: 0.9050
Early Stopping: val_loss did not lower, patience 2/5
saving the latest model (epoch 25, total_steps 1585)
loaded mean / std from cache
saving the model at the end of epoch 25, iters 1650
learning rate = 0.0002000
Epoch 25/40 | time: 437.1921 - train_acc: 80.30% - train_loss: 0.5418 - val_acc: 75.00% - val_loss: 0.5166
saving the latest model (epoch 26, total_steps 1651)
loaded mean / std from cache
saving the model at the end of epoch 26, iters 1716
learning rate = 0.0002000
Epoch 26/40 | time: 437.2484 - train_acc: 66.67% - train_loss: 0.5666 - val_acc: 58.33% - val_loss: 0.9042
Early Stopping: val_loss did not lower, patience 2/5
saving the latest model (epoch 27, total_steps 1717)
loaded mean / std from cache
saving the model at the end of epoch 27, iters 1782
learning rate = 0.0002000
Epoch 27/40 | time: 438.6410 - train_acc: 83.33% - train_loss: 0.5536 - val_acc: 66.67% - val_loss: 0.4789
saving the latest model (epoch 28, total_steps 1783)
loaded mean / std from cache
saving the model at the end of epoch 28, iters 1848
learning rate = 0.0002000
Epoch 28/40 | time: 435.3443 - train_acc: 78.79% - train_loss: 0.4698 - val_acc: 83.33% - val_loss: 0.3948
saving the latest model (epoch 29, total_steps 1849)
loaded mean / std from cache
saving the model at the end of epoch 29, iters 1914
learning rate = 0.0001818
Epoch 29/40 | time: 433.7931 - train_acc: 78.79% - train_loss: 0.4939 - val_acc: 58.33% - val_loss: 0.6411
Early Stopping: val_loss did not lower, patience 1/5
saving the latest model (epoch 30, total_steps 1915)
loaded mean / std from cache
saving the model at the end of epoch 30, iters 1980
learning rate = 0.0001636
Epoch 30/40 | time: 435.1726 - train_acc: 77.27% - train_loss: 0.5545 - val_acc: 66.67% - val_loss: 0.5583
saving the latest model (epoch 31, total_steps 1981)
loaded mean / std from cache
saving the model at the end of epoch 31, iters 2046
learning rate = 0.0001455
Epoch 31/40 | time: 435.2417 - train_acc: 87.88% - train_loss: 0.4811 - val_acc: 83.33% - val_loss: 0.5523
saving the latest model (epoch 32, total_steps 2047)
loaded mean / std from cache
saving the model at the end of epoch 32, iters 2112
learning rate = 0.0001273
Epoch 32/40 | time: 436.0455 - train_acc: 75.76% - train_loss: 0.4878 - val_acc: 75.00% - val_loss: 0.5157
saving the latest model (epoch 33, total_steps 2113)
loaded mean / std from cache
saving the model at the end of epoch 33, iters 2178
learning rate = 0.0001091
Epoch 33/40 | time: 432.7864 - train_acc: 90.91% - train_loss: 0.3756 - val_acc: 75.00% - val_loss: 0.5306
Early Stopping: val_loss did not lower, patience 1/5
saving the latest model (epoch 34, total_steps 2179)
loaded mean / std from cache
saving the model at the end of epoch 34, iters 2244
learning rate = 0.0000909
Epoch 34/40 | time: 433.9415 - train_acc: 72.73% - train_loss: 0.3234 - val_acc: 50.00% - val_loss: 0.9866
Early Stopping: val_loss did not lower, patience 2/5
saving the latest model (epoch 35, total_steps 2245)
loaded mean / std from cache
saving the model at the end of epoch 35, iters 2310
learning rate = 0.0000727
Epoch 35/40 | time: 436.1971 - train_acc: 89.39% - train_loss: 0.5338 - val_acc: 66.67% - val_loss: 0.8059
saving the latest model (epoch 36, total_steps 2311)
loaded mean / std from cache
saving the model at the end of epoch 36, iters 2376
learning rate = 0.0000545
Epoch 36/40 | time: 434.2258 - train_acc: 89.39% - train_loss: 0.2849 - val_acc: 66.67% - val_loss: 0.7909
saving the latest model (epoch 37, total_steps 2377)
loaded mean / std from cache
saving the model at the end of epoch 37, iters 2442
learning rate = 0.0000364
Epoch 37/40 | time: 433.2944 - train_acc: 87.88% - train_loss: 0.2795 - val_acc: 75.00% - val_loss: 0.8916
Early Stopping: val_loss did not lower, patience 1/5
saving the latest model (epoch 38, total_steps 2443)
loaded mean / std from cache
saving the model at the end of epoch 38, iters 2508
learning rate = 0.0000182
Epoch 38/40 | time: 434.0916 - train_acc: 89.39% - train_loss: 0.3137 - val_acc: 66.67% - val_loss: 0.7870
saving the latest model (epoch 39, total_steps 2509)
loaded mean / std from cache
saving the model at the end of epoch 39, iters 2574
learning rate = 0.0000000
Epoch 39/40 | time: 432.3801 - train_acc: 93.94% - train_loss: 0.2212 - val_acc: 75.00% - val_loss: 0.6812
saving the latest model (epoch 40, total_steps 2575)
loaded mean / std from cache
saving the model at the end of epoch 40, iters 2640
learning rate = -0.0000182
Epoch 40/40 | time: 432.6318 - train_acc: 93.94% - train_loss: 0.2187 - val_acc: 75.00% - val_loss: 0.6900
Early Stopping: val_loss did not lower, patience 1/5
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/Nodule-98-30K-GS-2022_07_08__02_34_24/latest_net.pth
Mesh         Prediction    Actual
-----------  ------------  --------
110-Izq.obj  nonodule      nodule
117-Izq.obj  nodule        nodule
161-Izq.obj  nodule        nodule
216-Izq.obj  nonodule      nodule
229-Izq.obj  nonodule      nodule
346-Izq.obj  nonodule      nodule
456-Izq.obj  nodule        nodule
475-Izq.obj  nodule        nodule
564-Izq.obj  nonodule      nodule
95-Izq.obj   nonodule      nodule
1-Izq.obj    nonodule      nonodule
15-Izq.obj   nodule        nonodule
19-Izq.obj   nonodule      nonodule
21-Izq.obj   nodule        nonodule
22-Izq.obj   nonodule      nonodule
23-Izq.obj   nonodule      nonodule
35-Izq.obj   nonodule      nonodule
43-Izq.obj   nonodule      nonodule
50-Izq.obj   nonodule      nonodule
7-Izq.obj    nodule        nonodule
Reporte de clasificación:
              precision    recall  f1-score   support

      nodule       0.57      0.40      0.47        10
    nonodule       0.54      0.70      0.61        10

    accuracy                           0.55        20
   macro avg       0.55      0.55      0.54        20
weighted avg       0.55      0.55      0.54        20

epoch: -1, TEST ACC: [55.00%], LOSS: 0.879

------------ Options -------------
amsgrad: False
arch: mconvnet
batch_size: 1
beta1: 0.9
checkpoints_dir: ./checkpoints
continue_train: False
csv: True
dataroot: ./data/datasets/Nodule-98-30K
dataset_mode: classification
dropout: [0.5, 0.25, 0.125]
epoch_count: 1
export_folder: 
fc_n: [1024, 512, 128]
flip_edges: 0.4
gpu_ids: [0]
init_gain: 0.02
init_type: kaiming
is_train: True
lr: 0.0002
lr_decay_iters: 50
lr_policy: lambda
max_dataset_size: inf
name: Nodule-98-30K-GS-2022_07_08__07_27_32
ncf: [256, 128, 64, 32]
ninput_edges: 30000
niter: 30
niter_decay: 10
no_vis: False
norm: batch
num_aug: 40
num_groups: 16
num_threads: 2
optimizer: rmsprop
phase: train
plus: False
pool_res: [20000, 15000, 10000, 5000]
print_freq: 9999
resblocks: 0
run_test_freq: 9999
save_epoch_freq: 1
save_latest_freq: 250
scale_verts: True
seed: 16
serial_batches: False
slide_verts: 0.4
validation: True
verbose_plot: False
verbose_train: True
which_epoch: latest
-------------- End ----------------
loaded mean / std from cache
#training meshes = 66
---------- Network initialized -------------
[Network] Total number of parameters : 0.847 M
-----------------------------------------------
saving the latest model (epoch 1, total_steps 1)
!WARNING! Queue below 100 edges on mesh 36-Izq.obj
Traceback (most recent call last):
  File "./networks/MeshCNNPlus/development/meshcnn/train.py", line 104, in <module>
    model.optimize_parameters()
  File "/mnt/homeGPU/vlugli/tfg/networks/MeshCNNPlus/development/meshcnn/models/mesh_classifier.py", line 84, in optimize_parameters
    out = self.forward()
  File "/mnt/homeGPU/vlugli/tfg/networks/MeshCNNPlus/development/meshcnn/models/mesh_classifier.py", line 75, in forward
    out = self.net(self.edge_features, self.mesh)
  File "/mnt/homeGPU/vlugli/condaEnvs/meshcnnplus/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/mnt/homeGPU/vlugli/condaEnvs/meshcnnplus/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py", line 159, in forward
    return self.module(*inputs[0], **kwargs[0])
  File "/mnt/homeGPU/vlugli/condaEnvs/meshcnnplus/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/mnt/homeGPU/vlugli/tfg/networks/MeshCNNPlus/development/meshcnn/models/networks.py", line 165, in forward
    x = getattr(self, 'pool{}'.format(i))(x, mesh)
  File "/mnt/homeGPU/vlugli/tfg/networks/MeshCNNPlus/development/meshcnn/models/layers/mesh_pool.py", line 21, in __call__
    return self.forward(fe, meshes)
  File "/mnt/homeGPU/vlugli/tfg/networks/MeshCNNPlus/development/meshcnn/models/layers/mesh_pool.py", line 34, in forward
    self.__pool_main(mesh_index)
  File "/mnt/homeGPU/vlugli/tfg/networks/MeshCNNPlus/development/meshcnn/models/layers/mesh_pool.py", line 51, in __pool_main
    value, edge_id = heappop(queue)
IndexError: index out of range
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/Nodule-98-30K-GS-2022_07_08__07_27_32/latest_net.pth
/mnt/homeGPU/vlugli/condaEnvs/meshcnnplus/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/mnt/homeGPU/vlugli/condaEnvs/meshcnnplus/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/mnt/homeGPU/vlugli/condaEnvs/meshcnnplus/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Mesh         Prediction    Actual
-----------  ------------  --------
110-Izq.obj  nonodule      nodule
117-Izq.obj  nonodule      nodule
161-Izq.obj  nonodule      nodule
216-Izq.obj  nonodule      nodule
229-Izq.obj  nonodule      nodule
346-Izq.obj  nonodule      nodule
456-Izq.obj  nonodule      nodule
475-Izq.obj  nonodule      nodule
564-Izq.obj  nonodule      nodule
95-Izq.obj   nonodule      nodule
1-Izq.obj    nonodule      nonodule
15-Izq.obj   nonodule      nonodule
19-Izq.obj   nonodule      nonodule
21-Izq.obj   nonodule      nonodule
22-Izq.obj   nonodule      nonodule
23-Izq.obj   nonodule      nonodule
35-Izq.obj   nonodule      nonodule
43-Izq.obj   nonodule      nonodule
50-Izq.obj   nonodule      nonodule
7-Izq.obj    nonodule      nonodule
Reporte de clasificación:
              precision    recall  f1-score   support

      nodule       0.00      0.00      0.00        10
    nonodule       0.50      1.00      0.67        10

    accuracy                           0.50        20
   macro avg       0.25      0.50      0.33        20
weighted avg       0.25      0.50      0.33        20

epoch: -1, TEST ACC: [50.00%], LOSS: 57.761

