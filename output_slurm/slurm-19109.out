------------ Options -------------
amsgrad: True
arch: mconvnet
batch_size: 1
beta1: 0.9
checkpoints_dir: ./checkpoints
continue_train: False
csv: True
dataroot: ./data/datasets/Nodule-50-30K
dataset_mode: classification
dropout: [0.0]
epoch_count: 1
export_folder: 
fc_n: [100]
flip_edges: 0.2
gpu_ids: [0]
init_gain: 0.02
init_type: normal
is_train: True
lr: 0.0002
lr_decay_iters: 50
lr_policy: lambda
max_dataset_size: inf
name: Nodule-50-30K-7
ncf: [16, 16, 32, 64]
ninput_edges: 30000
niter: 50
niter_decay: 50
no_vis: False
norm: batch
num_aug: 2
num_groups: 1
num_threads: 2
optimizer: adam
phase: train
plus: False
pool_res: [20000, 15000, 8000, 7500]
print_freq: 9999
resblocks: 0
run_test_freq: 9999
save_epoch_freq: 1
save_latest_freq: 250
scale_verts: False
seed: 16
serial_batches: False
slide_verts: 0.2
validation: True
verbose_plot: False
verbose_train: True
which_epoch: latest
-------------- End ----------------
loaded mean / std from cache
#training meshes = 34
---------- Network initialized -------------
[Network] Total number of parameters : 0.021 M
-----------------------------------------------
saving the latest model (epoch 1, total_steps 1)
loaded mean / std from cache
saving the model at the end of epoch 1, iters 34
learning rate = 0.0002000
Epoch 1/100 | time: 192.8225 - train_acc: 50.00% - train_loss: 0.6950 - val_acc: 50.00% - val_loss: 0.6940
saving the latest model (epoch 2, total_steps 35)
loaded mean / std from cache
saving the model at the end of epoch 2, iters 68
learning rate = 0.0002000
Epoch 2/100 | time: 191.0744 - train_acc: 50.00% - train_loss: 0.6951 - val_acc: 50.00% - val_loss: 0.6940
Early Stopping: val_loss did not lower, patience 1/5
saving the latest model (epoch 3, total_steps 69)
loaded mean / std from cache
saving the model at the end of epoch 3, iters 102
learning rate = 0.0002000
Epoch 3/100 | time: 191.2529 - train_acc: 50.00% - train_loss: 0.6941 - val_acc: 50.00% - val_loss: 0.6938
saving the latest model (epoch 4, total_steps 103)
loaded mean / std from cache
saving the model at the end of epoch 4, iters 136
learning rate = 0.0002000
Epoch 4/100 | time: 191.5231 - train_acc: 50.00% - train_loss: 0.6936 - val_acc: 50.00% - val_loss: 0.6938
saving the latest model (epoch 5, total_steps 137)
loaded mean / std from cache
saving the model at the end of epoch 5, iters 170
learning rate = 0.0002000
Epoch 5/100 | time: 191.3192 - train_acc: 50.00% - train_loss: 0.6938 - val_acc: 50.00% - val_loss: 0.6938
Early Stopping: val_loss did not lower, patience 1/5
saving the latest model (epoch 6, total_steps 171)
loaded mean / std from cache
saving the model at the end of epoch 6, iters 204
learning rate = 0.0002000
Epoch 6/100 | time: 191.2956 - train_acc: 50.00% - train_loss: 0.6937 - val_acc: 50.00% - val_loss: 0.6938
Early Stopping: val_loss did not lower, patience 2/5
saving the latest model (epoch 7, total_steps 205)
loaded mean / std from cache
saving the model at the end of epoch 7, iters 238
learning rate = 0.0002000
Epoch 7/100 | time: 192.6834 - train_acc: 50.00% - train_loss: 0.6933 - val_acc: 50.00% - val_loss: 0.6938
Early Stopping: val_loss did not lower, patience 3/5
saving the latest model (epoch 8, total_steps 239)
loaded mean / std from cache
saving the model at the end of epoch 8, iters 272
learning rate = 0.0002000
Epoch 8/100 | time: 191.6662 - train_acc: 50.00% - train_loss: 0.6927 - val_acc: 50.00% - val_loss: 0.6938
Early Stopping: val_loss did not lower, patience 4/5
saving the latest model (epoch 9, total_steps 273)
loaded mean / std from cache
saving the model at the end of epoch 9, iters 306
learning rate = 0.0002000
Epoch 9/100 | time: 191.4289 - train_acc: 50.00% - train_loss: 0.6937 - val_acc: 50.00% - val_loss: 0.6940
Early Stopping: val_loss did not lower, patience 5/5
saving the latest model (epoch 10, total_steps 307)
loaded mean / std from cache
saving the model at the end of epoch 10, iters 340
learning rate = 0.0002000
Epoch 10/100 | time: 193.0515 - train_acc: 50.00% - train_loss: 0.6928 - val_acc: 50.00% - val_loss: 0.6949
Early Stopping: val_loss did not lower, patience 6/5
Validation loss is stagnating, stopping.
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/Nodule-50-30K-7/latest_net.pth
/mnt/homeGPU/vlugli/condaEnvs/meshcnnplus/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/mnt/homeGPU/vlugli/condaEnvs/meshcnnplus/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/mnt/homeGPU/vlugli/condaEnvs/meshcnnplus/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Mesh         Prediction    Actual
-----------  ------------  --------
110-Izq.obj  nonodule      nodule
203-Izq.obj  nonodule      nodule
213-Izq.obj  nonodule      nodule
218-Izq.obj  nonodule      nodule
269-Izq.obj  nonodule      nodule
11-Izq.obj   nonodule      nonodule
23-Izq.obj   nonodule      nonodule
25-Izq.obj   nonodule      nonodule
28-Izq.obj   nonodule      nonodule
5-Izq.obj    nonodule      nonodule
Reporte de clasificaci√≥n:
              precision    recall  f1-score   support

      nodule       0.00      0.00      0.00         5
    nonodule       0.50      1.00      0.67         5

    accuracy                           0.50        10
   macro avg       0.25      0.50      0.33        10
weighted avg       0.25      0.50      0.33        10

epoch: -1, TEST ACC: [50.00%], LOSS: 0.692

